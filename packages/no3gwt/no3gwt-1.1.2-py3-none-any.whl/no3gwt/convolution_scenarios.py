"""
This file represents the core of the GW-NDST software.  It contains 
numerous functions, most of which support the two main scenario functions:
historican_simulation and future_scenarios.  
"""

import os, sys, time
import numpy as np
import pandas as pd
from pyproj import CRS
import geopandas as gpd
import gzip
import osgeo
import rasterio
from scipy.interpolate import interp1d
from scipy.optimize import minimize
import math
from datetime import datetime
from matplotlib import pyplot as plt
from matplotlib.legend_handler import HandlerTuple
from matplotlib.lines import Line2D
import matplotlib.patches as mpatches
from matplotlib.backends.backend_pdf import PdfPages
import random
from shapely.geometry import Point, shape, MultiPolygon
from no3gwt import well_setup as ws
import pkg_resources
from no3gwt.config import *

def age_distrib_ML(user_df, well, params, N_input_df):
    '''This function takes in the well information generated by the ageML
    model and the geospatial methods. It uses the mean age from the ageML model
    to calculate an age distribution for the well. The IBIS input (N_input_df) 
    is used only to pull-out recharge, which is then used to estimate UZ_time.
    
    Outputs from this function are vectors of travel time, probability of 
    travel times, unsaturated zone travel time, and a sum of the probability 
    density function to check the age distribution sums to 1.
    '''
    # Maximum groundwater age set to 2000 years.
    t, tt, g_t, dt, uz_tt = ([*np.arange(0, 2000, 1, dtype = 'int64')] 
                             for i in range(5))  

    for i in range(1, len(t)):
        t[i] = round(t[i] , 2)

    disp_ratio = params['disp_ratio']
    uz_mobile = params['uz_mobile']
    uz_thick = params['uz_thick']
    age_mult = params['age_mult']
    flux_mult = params['flux_mult']
    
    N_input = N_input_df[['Time', f'NO3_Leaching_{well}', 
                          f'Drainage_Flux_{well}']]
    
    # long-term ave R from IBIS at well.
    recharge = (np.mean(N_input[f'Drainage_Flux_{well}'].values)
                * flux_mult)/1000  
    
    uz_v = recharge/uz_mobile
    uz_mean_tt = uz_thick/uz_v 
        
    mean_tt = age_mult*(user_df.loc[well, 'total_tt_years']) 
    gw_tt = mean_tt - uz_mean_tt 
    
    R = 0.5 * ((math.erf((0.26082 * math.log(disp_ratio)) - 0.95381)) + 1)
    S = 13.64867 * (mean_tt ** 0.997541) / (disp_ratio ** 0.592066)
    
    A_check = (gw_tt - (R * S) + (R + gw_tt)) / (R + 1)
    
    if A_check >= 0.0001:
        A = A_check
    else:
        A = 0.0001
        
    B = (A + S) * 1
    step1 = ( (B - A) * (1 - 1.0025) ) /  (1 - 1.0025**399 )

    g_t[0] = 0.
    uz_tt[0] = 0.
    for i in range(1, len(t)):
        tt[i] = tt[i-1] + ((step1) * ((1.0025) ** t[i-1]))
        g_t[i] = (disp_ratio*np.sqrt(mean_tt)/np.sqrt(4*np.pi*disp_ratio
                *(np.power(tt[i],3))))*np.exp((-1*(disp_ratio*(mean_tt/4))
                /tt[i])*(np.power(1 - (tt[i]/mean_tt), 2)))

        uz_tt[i] = (tt[i]*uz_mean_tt)/(mean_tt)
        dt[i] = tt[i] - tt[i - 1]
    
    check = np.array(g_t)*np.array(dt)
    sumPDF = sum(check)
    
    return tt, g_t, uz_tt, dt, sumPDF

def age_distrib_MP(MP_age_distrib_dict, well, params, N_input_df):

    data = MP_age_distrib_dict
    tt = np.array(data['tt'])
    g_t = np.array(data['g_t'])
    dt = np.array(data['dt'])
    mean_tt = data['mean_tt']
    sumPDF = data['sumPDF']
        
    uz_mobile = params['uz_mobile']
    uz_thick = params['uz_thick']
    flux_mult = params['flux_mult']
    
    N_input = N_input_df[['Time', f'NO3_Leaching_{well}', 
                          f'Drainage_Flux_{well}']]
    
    # long-term average recharge from agro-IBIS at well location.
    recharge = (np.mean(N_input[f'Drainage_Flux_{well}'].values)
            *flux_mult)/1000  
    
    uz_v = recharge/uz_mobile
    uz_mean_tt = uz_thick/uz_v 
        
    uz_tt = [(i*uz_mean_tt)/(mean_tt) for i in tt]
            
    return tt, g_t, uz_tt, dt, sumPDF

def Y_interp(y, N_join, dates_interp):
    '''This small function takes a list of years (y), database of NO3 leaching
    values (N_join), and dates to be interpreted across, (dates_interp) and
    interpolates (possibily into the future), returning a database of
    interpolated NO3 leaching values (N_sum) and drainage (Drain) values to be
    used for convolution. The NO3 leaching values should be in lb/ac, and will
    be output in lb/ac. The drainage values should be in mm/year. Conversion
    to kg/ha and then mg/L happens in the N_con_calc function later.
    '''
    sum_interp = interp1d(y, N_join['N_sum'].values, fill_value="extrapolate")
    drain_interp = interp1d(y, N_join['Drain'].values, fill_value="extrapolate")
    N_interp = sum_interp(dates_interp)
    drain_interped = drain_interp(dates_interp)
    N_join_interp = pd.DataFrame({'N_sum': N_interp, 'Drain' : drain_interped}, 
                                 index = dates_interp)
    return N_join_interp

def input_slope_adjust(mult1, mult2, data):
    mults = np.linspace(mult1, mult2, len(data))
    new_vals = mults*data
    new_vals[new_vals <= 0] = 0.001
    new_data = pd.Series(data = new_vals, index = data.index, name = data.name)
    
    return new_data

def N_interpolate(user_df, well, sample_date, params, sep_input_df, N_input_df,
                  MP_flag = False):
    ''' This function takes the well information generated earlier by the ageML
    model and the geospatial methods in addition to a "sample date" associated 
    with a well.  It pulls in the  appropriate septic and N data generated by
    septic_pull and IBIS_pull. This function calculates total N leached by 
    adding septic to IBIS. The function then creates vectors of dates and N 
    leaching values based on the sample date, interpolating between decades of
    septic data and integer years of N leached, and converting to the more 
    irregular dates used in the age distribution(using the Y_interp function 
    above). Outputs from this function are a database of years and N leached 
    (N_join), database (N_interp) of interpolated N leached (N_sum) and 
    Drainage fluxes (Drain), and associated dates (N_dt).
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_ML(user_df, well, 
                                                    params, N_input_df)
    else:
        tt, g_t,uz_tt,dt, sumPDF = age_distrib_MP(MP_flag, well, 
                                                  params, N_input_df)
    flux_mult = params['flux_mult']  

    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + float(dat.strftime("%Y"))
    samp_year = int(np.floor(smp_dt))

    dates = [*np.arange(0, len(tt), 1)]
    y = np.linspace(1850, samp_year, (samp_year - 1850) + 1, 
                    endpoint= True, dtype = int)

    sep_input = sep_input_df[['Year', f'Sep_leach_{well}']]

    N_input = N_input_df[['Time', f'NO3_Leaching_{well}', 
                          f'Drainage_Flux_{well}']]

    N_dat = N_input['Time'].values
    N_input_dates = [pd.to_datetime(i).year for i in N_dat]

    N_input_dt = N_input.drop('Time', axis = 1)
    N_input_dt['Year'] = N_input_dates
    N_input_dt.set_index('Year', inplace = True)
    sep_input.set_index('Year', inplace = True)

    septic_mult, ibis_mult = params['septic_mult'], params['ibis_mult']
    
    N_metric = pd.merge(sep_input, N_input_dt, on='Year', how='left').fillna(0)
    N_metric['N_sum'] = np.nan_to_num(septic_mult * 
                            N_metric[f'Sep_leach_{well}'] + 
                            ibis_mult * 
                            N_metric[f'NO3_Leaching_{well}']) 
                            #NO3_Leaching is in kg/ha from agro-IBIS
    
    N_join = N_metric.copy()
    N_join['N_sum'] = N_join['N_sum'] * 0.892179  # Result is in lb/ac
    N_join['Drain'] = N_join['Drainage_Flux_{}'.format(well)] * flux_mult

    for i in N_join.index:
        if i > 2014:
            N_join.loc[i, 'N_sum'] = N_join.loc[2014, 'N_sum']
            N_join.loc[i, 'Drain'] = N_join['Drain'].mean()
    for i in N_join.index:
        if i < 1901:
            N_join.loc[i, 'Drain'] = N_join.loc[1901:]['Drain'].min()

    # Pull out and apply multiplier parameters for early and later-periods.
    mult1, mult2 = params['is_start_mult'], params['is_end_mult'] 
    N_join['N_sum'] = input_slope_adjust(mult1, mult2, N_join.N_sum)
    N_complete = N_join.copy()    
    N_join = N_join.loc[1850:samp_year]
    
    for i in range(0, len(dates)):
        dates[i] = smp_dt - tt[i]

    dates_interp = [i for i in dates if i >= 1850]

    N_interp = Y_interp(y, N_join, dates_interp) 
    
    # N_join is the dataframe of NO3 leaching for each year through sample 
    # year.  Note that sample_date (year) typically represent either the most
    # recent sample date or the date tool is run.
    # N_interp[N_sum] is the leaching rate in lb/ac with variable dates 
    # for convolution, and N_interp[Drain] is mm/year, interpolated to the age 
    # distrib dates for convolution. N_complete is the same as N_join (per year) 
    # but goes through 2020.
    
    return N_join, N_interp, dates_interp, N_complete
  
def N_con_calc(N_interp, user_df, well, params, N_input_df, MP_flag = False):
    ''' This function takes the output from the age_distrib function, the 
    interpolated N_loading input values (lb/acre), and Drainage fluxes
    (mm/year) to perform a convolution, yielding an NO3 concentration value 
    for the sample date.

    Interpolated N loading and drainage (from N_interp), using N_interpolate
    function, must be created for the specified "sample date" or date at which
    the convolution should be calculated.
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_ML(user_df, well, params, 
                                                                N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_MP(MP_flag, well, params, 
                                                                N_input_df)

    N_dt, N_con = (np.zeros(len(N_interp)) for i in range(2))
    dt = dt[0:len(N_interp)]
    
    k_NO3 = params['k_no3']     # zero-order denitrification rate coefficient
    O2_cut = params['o2_cut']   # cut off O2 conc to start denitrification
    k_O2 = params['k_o2']       # zero-order O2 reaction rate coefficient
    # Time to go from fully oxygenated to reducing.
    O2_lag = (O2_init - O2_cut)/k_O2 
    
    # N_interp['N_sum'] is nutrient source from IBIS + septic in lb/acre.
    # N_interp['Drain'] is recharge flux from IBIS in mm/year.
    # Create new column of N_conc in mg/L for convolution.
    N_interp = N_interp.assign(
            N_conc = ((N_interp['N_sum']*1.12085)/N_interp['Drain'])*100)
    
    for i, dat2 in enumerate(N_interp.index):
        #convolution should take in mg/L
        N_dt[i] = N_interp.loc[dat2, 'N_conc']
        
        # duration of reducing conditions.
        tt_O = (tt[i] - uz_tt[i] - O2_lag)  
        if tt_O <= 0:
            tt_O = 0
        else:
            tt_O = tt_O
        
        # the convolution (conc @ each moment)
        N_con[i] = (g_t[i]/sumPDF)*(N_dt[i] - k_NO3*(tt_O))  
        
        if N_con[i] <= 0:
            N_con[i] = 0
        else:
            N_con[i] = N_con[i]
    # conc for the duration between moments
    check = np.array(N_con)*np.array(dt)
    # sum of conc across all durations. Output is mg/L
    sumN = sum(check)  
    
    return sumN

def N_convolve(user_df, well, sample_date, params, sep_input_df, N_input_df, 
               MP_flag):
    '''This function uses above functions to calculate a convolution-
        generated N value.
    '''
    N_join, N_interp, dates_interp, N_total = N_interpolate(
            user_df, well, sample_date, params, sep_input_df, N_input_df, 
            MP_flag)
    
    sumN = N_con_calc(N_interp, user_df, well, params, N_input_df, MP_flag)
    
    return sumN

def convolution_output_pest(user_df, params, sep_input_df, N_input_df,
                            grid_pars=None, save_cutoff_well_info=True,
                            setup_run=False):
    '''
    This function uses above functions to run the NDST convolution process for
    PEST calibration only. 
    
    Parameters
    ----------
    user_df : pandas dataframe; 
        full user data with ageML output) (and optionally wt-ml, and redox 
        output) as a pandas df. 
    params : dict; 
        model parameter dictionary. Values contianed in 
        'pest/NDST_script_parvals.txt'.
    sep_input_df : pandas dataframe;
        output from pull_septic fuction. Septic leaching time series, one 
        column corresponds to each well (row) in user_df and user_df
    N_input_df : pandas dataframe;
        output from pull_IBIS. NO3 leaching and drainage flux, two columns 
        correspond to each well (row) in user_df and user_df
    grid_pars : list (optional);
        list of gridded parameters to use. If None, use fixed values in 
        params
    save_cutoff_well_info : bool (default = True);
        export csv file that contains original simulated nitrate values and 
        other well info from wells with simulated nitrate 
        concentration less than 0.0001 mg/L cutoff. 
    setup_run : bool (default = False);
        flag for pre-parameterization run. skips convolution and populates 
        output with dummy values (all 0.1's) to save (lots of) time. Real 
        numbers are then generated during noptmax=0.
    
    '''
    no3_calc = []
    obs_name = []
    print("starting convolution:")
    for i in user_df.index:
        #  progress tracker, for when there are a lot of wells
        if i == 1 or i%1000==0:
            print(f'On sample {i}...\r', end="")

        if grid_pars != None:
            # update pars dictionary 
            for par in grid_pars:
                params[f'{par}'] = user_df.loc[i, f'{par}']

        obs_date = user_df.loc[i, 'sample_dt']
        sample_date = datetime.strptime(
                obs_date, "%Y-%m-%d").strftime('%m/%d/%Y')
        site_no = user_df.loc[i, 'site_no'].lower()

        if setup_run is False:
            no3_calc.append(N_convolve(user_df, i, sample_date, params, 
                                       sep_input_df, N_input_df, 
                                       MP_flag=False))
        elif setup_run is True:
            no3_calc.append(0.1)
        
        if len(site_no) > 10:
            obs_name.append(f'nawqa_{site_no}_{obs_date}_no3')
        else:
            obs_name.append(f'wi_dnr_{site_no}_{obs_date}_no3')
    final_output = pd.DataFrame(list(zip(obs_name, no3_calc)), 
                                columns=['OBSNME', 'SIMVAL']) 

    #  aggregate details about wells with simulated nitrate below 
    #  0.0001 mg/L and export as csv
    if save_cutoff_well_info is True:
        output_below_cutoff = final_output.loc[final_output.SIMVAL<0.0001]
        user_df['source'] = np.nan

        nawqa_mask = user_df.site_no.astype(str).str.len()>10
        wi_dnr_mask = user_df.site_no.astype(str).str.len()<10

        user_df.loc[nawqa_mask, 'source'] = 'nawqa'
        user_df.loc[wi_dnr_mask, 'source'] = 'wi_dnr'
        user_df['OBSNME'] = user_df['source'].astype(str) + '_' \
                + user_df.index.astype(str) + '_no3'
        
        output_below_cutoff = output_below_cutoff.merge(
            user_df[['site_no', 'sample_dt', 'latitude_deg',
            'longitude_deg', 'lev_va_merge_nwis_ft',
            'scrndepbot_ft', 'scrndeptop_ft', 'NO3_obs',
            'OBSNME']], how='left', on='OBSNME')
        output_below_cutoff.to_csv('cutoff_well_info.csv', index=False)

    # Replace simultated nitrate values less than 0.0001 mg/L with 0.0001 mg/L.
    # Exceedingly low simulated concentrations dilute the calibration signol
    # for calibration (plus are below detection).
    final_output.loc[final_output.SIMVAL<0.0001, 'SIMVAL'] = 0.0001
    
    return final_output

def build_mc_df(x_coord, y_coord, crs, grid_file_path, par_ens_path, grid_pars,
                grid_pars_path):
    '''
    Function to build parameter ensemble dataframe for MC GUI utility, for any 
    set of x-y coordinate in Wisconsin
    
    Parameters
    ----------
    x_coord : longitude, float; 
    y_coord : latitude, float;
    crs : pyproj.CRS coordinate reference object;
        crs of of x and y coords
    grid_file_path : str, path;
        local path to `natlGrid_WIbuff_block.tif`
    par_ens_path : str, path;
        local path to optimal ies parameter ensemble
    grid_pars : list;
        list of grid parameters (see example usage below)
    grid_pars_path: str, path;
        local path to grid pars npy.gz files
    ----------
    Example Usage: 

        grid_pars = [
            'disp_ratio', 'uz_mobile', 'k_o2_mult',
            'age_mult', 'ibis_mult', 'is_start_mult',
            'is_end_mult', 'flux_mult'
            ]
        
        df = build_mc_df(
            x_coord=-88.28806, y_coord=42.66861, 
            crs=gdf.crs, 
            grid_file_path = '../data_in/gis/NationalGrid/natlGrid_WIbuff_block.tif',
            par_ens_path=os.path.join(rundir,'ndst_merge_psr4.2.par.csv'),
            grid_pars=grid_pars, 
            grid_pars_path='../pest/ies_parameter_ensembles/'
            )
    ----------
    '''
    assert crs is not None
    s = gpd.GeoSeries(Point(x_coord, y_coord), crs=crs)
    
    with rasterio.open(grid_file_path) as src:
        grid_crs = src.crs
        s_reproj = s.to_crs(grid_crs)
        x_coord_reproj = s_reproj.x[0]
        y_coord_reproj = s_reproj.y[0]
        row, col = src.index(x_coord_reproj, y_coord_reproj)
        
    par_ens = pd.read_csv(par_ens_path, index_col=0, dtype={'real_name': 
                                                                'string'})
    keep_cols = [i for i in par_ens.columns if '_pp_:' not in i]
    df = par_ens[keep_cols].copy()
    
    for par in grid_pars:
        f = gzip.GzipFile(os.path.join(grid_pars_path, f'{par}.npy.gz'), 'r')
        par_array = np.load(f)
        f.close()
        par_data = par_array[:, row, col]
        df[f'{par}'] = par_data 
    return df


##################################
# Functions for future scenarios #
##################################

def date_list(date, tt):
    '''This short function takes in a future date and creates a list of future
    dates to use for convolution. The function uses the travel time timeseries
    to create the future dates.
    '''
    dat = datetime.strptime(date, "%m/%d/%Y")
    smp_dt_fut = (float(dat.strftime("%j"))-1) / 365.25 + \
                                                    float(dat.strftime("%Y"))
    year = int(np.floor(smp_dt_fut))
    dates_future = [*np.arange(0, len(tt), 1)]
    y = np.linspace(1850, year, (year - 1850) + 1, endpoint=True, dtype=int)
    
    for i in range(0, len(dates_future)):
        dates_future[i] = smp_dt_fut - tt[i]
    dates_int_future = [i for i in dates_future if i >= 1850]
    dates_new = dates_int_future
    
    return dates_new, y, year

def future_frac(fraction, user_df, N_goal, well, fut_date, sample_date, 
                params, sep_input_df, N_input_df, MP_flag = False):
    '''This function computes the difference between a calculated NO3 value at
    a future date and a NO3_goal value.  The future NO3 inputs are a fraction
    of the 2020 NO3 input values where that fraction is an input that can be 
    optimized in a later function.
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_ML(
                user_df, well, params, N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_MP(
                MP_flag, well, params, N_input_df)
        
    N_join, N_interp, dates_interp, N_total = N_interpolate(
            user_df, well, sample_date, params, sep_input_df, N_input_df,
            MP_flag)

    this_year = datetime.today().year
    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + float(dat.strftime("%Y"))
    year_sample = int(np.floor(smp_dt))
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(this_year, 
                                            fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')
    N_sum_append = [N_total['N_sum'].values[-1]*fraction]*(fut_year - 
                                                                    this_year)
    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, 
                                                                      MP_flag)
    rate_prior = N_total['N_sum'].values[-1]
    
    return abs(sumN - N_goal)

def future_constant(rate, user_df, well, fut_date, sample_date, params, 
                    sep_input_df, N_input_df, MP_flag = False):
    '''This function computes the calculated NO3 value at a future date.
    The future NO3 inputs are a constant rate lb/ac given as an input. 
    Output also includes the 2020 rate for comparison.
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_ML(
                user_df, well, params,N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_MP(
                MP_flag, well, params, N_input_df)
        
    N_join, N_interp, dates_interp, N_total = N_interpolate(
            user_df, well, sample_date, params, sep_input_df, N_input_df, 
            MP_flag)

    this_year = datetime.today().year
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(this_year,
            fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')
    N_sum_append = [rate]*(num_years) # rate has units of lb/ac
    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, 
                                                                      MP_flag)
    rate_prior = N_total['N_sum'].values[-1]
    
    return sumN, rate_prior, N_interp_future, dates_int_future

def future_constant_uncert(rate, user_df, well, fut_date, sample_date, params,
                           params_base, perc_uncert, sep_input_df, N_input_df, 
                           percentile = 'med', MP_flag = False):
    '''This function computes the calculated NO3 value at a future date.
    The future NO3 inputs are a constant rate lb/ac given as an input. 
    Output also includes the 2020 rate for comparison. This version of the
    "future_constant" function is used with the Monte Carlo realizations.
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_ML(
                user_df, well, params, N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_MP(
                MP_flag, well, params, N_input_df)
        
    N_join, N_interp, dates_interp, N_total = N_interpolate(
            user_df, well, sample_date, params, sep_input_df, N_input_df, 
                                                                    MP_flag)

    this_year = datetime.today().year
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(
            this_year, fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')
    if percentile == 'max':
        N_sum_append = [rate + np.log((1+perc_uncert)**i) \
                for i in range(0,num_years)] 
        
    if percentile == 'min':
        N_sum_append = [rate + np.log((1-perc_uncert)**i) \
                for i in range(0,num_years)]
        N_sum_append = [0 if i<0 else i for i in N_sum_append]
    if percentile  == 'med':
        N_sum_append = [rate for i in range(0,num_years)]
        
    for i in range(0, num_years):
        if N_sum_append[i] < 0:
            N_sum_append[i] = 0    
    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, MP_flag)
    rate_prior = N_total['N_sum'].values[-1]
    return sumN, rate_prior, N_interp_future, dates_int_future

def opt_frac(frac_guess, user_df, N_goal, well, fut_date, sample_date, params,
             sep_input_df, N_input_df, shift, MP_flag = False, 
             print_out = True):
    '''This function optimizes the fraction by which NO3 should be applied 
    into the future to reach a certian NO3 goal by a certain sample date in 
    the future.
    '''
    
    if print_out:
        print1 = 'In order to reduce nitrate concentrations to {:.1f} ' \
                 'mg/L by {}: '.format(N_goal+shift, fut_date)
        print(print1)  
    
    res = minimize(future_frac, frac_guess, args = (
            user_df, N_goal, well, fut_date, sample_date, params, 
            sep_input_df, N_input_df, MP_flag),method = 'nelder-mead')
    
    min_N, rate_prior, N_interp_future, dates_int_future = future_constant(
            0, user_df, well, fut_date, sample_date, params, sep_input_df, 
            N_input_df, MP_flag)
    
    while res.x < 0:
        
        if min_N <= N_goal:
            frac_guess = 0
            res = minimize(future_frac, frac_guess, args = (
                    user_df, N_goal, well, fut_date,sample_date, params, 
                    sep_input_df, N_input_df, MP_flag), method = 'nelder-mead')
        
        else:
            frac_guess = frac_guess/10
            res = minimize(future_frac, frac_guess, args = (
                    user_df, N_goal, well, fut_date, sample_date, params, 
                    sep_input_df, N_input_df, MP_flag), method = 'nelder-mead')
        
    if res.fun > 0.001:
        if print_out:
            print2 = 'The goal concentration could not be met without '\
                     'removing legacy nitrate \nfrom the system.  The '\
                     'forecasted nitrate concentration on this date \n(by '\
                     'reducing the nitrate leaching rate to 0 lb/ac today) '\
                     'is: {:.1f} mg/L. \n'.format(round(min_N, 2))
            print3 = ''                     
            print4 = ''
            print(print2) 

    if res.fun <= 0.001:
        rate_new = res.x[0]*rate_prior
        rate_diff = rate_prior - rate_new
        
        if rate_diff < 0:
            if print_out:
                print2 = 'The nitrate leaching rate does not need to be '\
                         'reduced in order to \nreach the goal concentration. '\
                         ' This realization will be plotted \nbelow using the '\
                         'current leaching rate. \n'
                print3 = ''
                print4 = ''
                print(print2)
            
        if rate_diff > 0:
            if print_out:
                print2 = 'The nitrate leaching rate would need to be reduced '\
                         'by {:.0f}% from '.format(round(1 - res.x[0], 2)*100)
                print3 = '\na nitrate leaching rate of {:.1f} lb/ac to a ' \
                         'rate of {:.1f} lb/ac. '.format(
                         round(rate_prior, 2), round(rate_new, 2))
                
                print4 = '\nThis is an absolute drop of {:.1f} lb/ac in nitrate '\
                         'leaching.\n'.format(round(rate_diff, 2))
                print(print2, print3, print4)
              
    if print_out:
        print_statement = print1 + '\n' + print2 + print3 + print4
        return res.x[0], print_statement
    else:
        return res.x[0], rate_prior

def future_slope_calc(slope, user_df, well, fut_date, sample_date, params,
                      sep_input_df, N_input_df, MP_flag = False):
    '''This function calculates a convolution-generated NO3 value at a future
    date based on a certain slope starting starting on the date the NDST is 
    run and extending into the future. This function outputs the NO3 
    concentration as well as a date at which the NO3 leaching rate reaches 0
    (if it does) and the final rate on the target date (zero or otherwise).
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_ML(user_df, well, params, 
                                                    N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_MP(MP_flag, well, params, 
                                                    N_input_df)
        
    N_join, N_interp, dates_interp, N_total = N_interpolate(
            user_df, well, sample_date, params, sep_input_df, N_input_df,
            MP_flag)

    this_year = datetime.today().year
    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
              float(dat.strftime("%Y"))
    year_sample = int(np.floor(smp_dt))
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(
            this_year, fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')
    
    N_start = N_total['N_sum'].values[-1]
    t3 = np.linspace(1, num_years, num_years)
    N_sum_append = np.array(t3.copy(), dtype = np.float32)*0
    
    for i in range(0, num_years):
        N_sum_append[i] = N_start + slope*(i)
        if N_sum_append[i] < 0:
            N_sum_append[i] = 0
    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, 
                      MP_flag)
    
    if min(N_sum_append) == 0:
        idx = np.where(N_sum_append == 0)[0][0]
        N_year = N_join_append.reset_index()
        zero_date = N_year.loc[idx, 'Year']
        
    else:
        zero_date = 'N/A'
        
    final_rate = np.around(N_interp_future.N_sum.values[0], decimals = 3)
    
    return sumN, zero_date, final_rate, N_interp_future, dates_int_future

def future_slope_uncert_calc(slope, user_df, well, fut_date, sample_date, 
                             params, params_base, perc_uncert, sep_input_df,
                             N_input_df, percentile = 'med', MP_flag = False):
    '''This function calculates a convolution-generated NO3 value at a future 
    date based on a certain slope starting on the date the NDST is run and 
    extending into the future. This function outputs NO3 concentration as well 
    as a date at which the NO3 leaching rate reaches 0 (if it does)and the 
    final rate on the sample date (zero or otherwise).  This version of the
    "future_slope_calc" function is used with the Monte Carlo realizations.
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_ML(user_df, well, params, 
                                                    N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = age_distrib_MP(MP_flag, well, params, 
                                                    N_input_df)
        
    N_join, N_interp, dates_interp, N_total = N_interpolate(
            user_df, well, sample_date, params, sep_input_df, N_input_df,
            MP_flag)

    this_year = datetime.today().year
    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + float(
            dat.strftime("%Y"))
    year_sample = int(np.floor(smp_dt))
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(
            this_year, fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')

    N_start = N_total['N_sum'].values[-1]

    if percentile == 'max':
        N_sum_append = [N_start + slope*(i) + np.log((1+perc_uncert)**i) \
                for i in range(0,num_years)] 
    if percentile == 'min':
        N_sum_append = [N_start + slope*(i) + np.log((1-perc_uncert)**i) \
                for i in range(0,num_years)]
    if percentile == 'med':
        N_sum_append = [N_start + slope*(i) for i in range(0,num_years)]
        
    for i in range(0, num_years):
        if N_sum_append[i] < 0:
            N_sum_append[i] = 0

    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, 
                      MP_flag)
    
    if min(N_sum_append) == 0:
        idx = np.argmin(N_sum_append)
        N_year = N_join_append.reset_index()
        zero_date = N_year.loc[idx, 'Year']
        
    else:
        zero_date = 'N/A'
        
    final_rate = np.around(N_interp_future.N_sum.values[0], decimals = 3)
    
    return sumN, zero_date, final_rate, N_interp_future, dates_int_future

def future_slope(slope, user_df, N_goal, well, fut_date, sample_date, params,
                 sep_input_df, N_input_df, MP_flag = False):
    '''This function calculates the absolute difference between a convolution-
    generated NO3 value on a future sample date and a N_goal on that date. The
    calculated NO3 value is from a future NO3 leaching rate that is generated 
    with a constant slope starting from the NO3 leaching rate on the date the 
    NDST is run. The slope is an input to this function as to be optimized in 
    a later function.
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_ML(user_df, well, params, N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_MP(MP_flag, well, params, N_input_df)
        
    N_join, N_interp, dates_interp, N_total = \
                             N_interpolate(user_df, well, sample_date, params,
                                           sep_input_df, N_input_df, MP_flag)

    this_year = datetime.today().year
    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
              float(dat.strftime("%Y"))
    year_sample = int(np.floor(smp_dt))
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(this_year, 
                                                fut_year, num_years, 
                                                dtype = int))
    N_join_append = N_join_append.set_index('Year')
    
    N_start = N_total['N_sum'].values[-1]
    t3 = np.linspace(1, num_years, num_years)
    N_sum_append = np.array(t3.copy(), dtype = np.float32)*0
    
    for i in range(0, num_years):
        N_sum_append[i] = N_start + slope*(i)
        if N_sum_append[i] < 0:
            N_sum_append[i] = 0
    
    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, 
                      MP_flag)
        
    return abs(sumN - N_goal)

def future_slope_uncert(slope, user_df, N_goal, well, fut_date, sample_date, 
                        params, params_base, perc_uncert, sep_input_df, 
                        N_input_df, percentile = 'med', MP_flag = False):
    '''This function calculates a convolution-generated NO3 value at a 
    future date based on a certain slope starting starting on the date the 
    NDST is run and extending into the future. This function outputs NO3 
    concentration as well as a date at which the NO3 leaching rate reaches 0
    (if it does) and the final rate on the sample date (zero or otherwise).
    This version of the "future_slope" function is used with the Monte Carlo
    realizations.
    '''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_ML(user_df, well, params, N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_MP(MP_flag, well, params, N_input_df)
        
    N_join, N_interp, dates_interp, N_total = \
                           N_interpolate(user_df, well, sample_date, params, 
                                         sep_input_df, N_input_df, MP_flag)

    this_year = datetime.today().year
    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
              float(dat.strftime("%Y"))
    year_sample = int(np.floor(smp_dt))
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = \
                     np.linspace(this_year, fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')

    N_start = N_total['N_sum'].values[-1]
    
    if percentile == 'max':
        # Rate is in lb/ac.
        N_sum_append = \
             [N_start + slope*(i) + np.log((1+perc_uncert)**i) 
              for i in range(0,num_years)] 
    if percentile == 'min':
        N_sum_append = \
             [N_start + slope*(i) + np.log((1-perc_uncert)**i) 
              for i in range(0,num_years)]
    if percentile == 'med':
        N_sum_append = [N_start + slope*(i) for i in range(0,num_years)]
        
    for i in range(0, num_years):
        if N_sum_append[i] < 0:
            N_sum_append[i] = 0

    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, 
                      MP_flag)
    
    return abs(sumN - N_goal)

def opt_slope(slope_guess, user_df, N_goal, well, fut_date, sample_date, 
              params, sep_input_df, N_input_df, shift, MP_flag = False, 
              print_out = True):
    '''This function optimizes the slope by which NO3 should be decreased (or 
    increased possibly) into the future to reach a certian NO3 goal 
    concentration by a certain sample date in the future.
    '''  
    if print_out:
        print1 = 'In order to reach nitrate concentrations of {:.1f} mg/L by {}:'.\
                 format(N_goal+shift, fut_date)
        print(print1)  
    
    res = minimize(future_slope, slope_guess, args = (user_df, N_goal, well, 
                                                      fut_date, sample_date,
                                                      params, sep_input_df, 
                                                      N_input_df, MP_flag),
                                              method = 'nelder-mead')  
    min_N, rate_prior, N_interp_future, dates_int_future = \
                                   future_constant(0, user_df, well, fut_date,
                                                   sample_date, params, 
                                                   sep_input_df, N_input_df, 
                                                   MP_flag)
    print2 = ''
    print3 = ''
    
    if res.fun > 0.001:
        if print_out:
            print2 = 'The goal concentration could not be met with a steady '\
                     'decrease \nof the nitrate leaching rate. The forecasted '\
                     'concentration on \nthis date (by reducing the leaching '\
                     'rate to 0 lb/ac starting \ntoday) is: {:.1f} mg/L.\n'\
                     .format(round(min_N, 2))
            print(print2)
    if res.fun <= 0.001:
        if res.x[0] < 0:
            sumN, zero_date, final_rate, N_interp_future, dates_int_future = \
                          future_slope_calc(res.x[0], user_df, well, fut_date,
                          sample_date, params, sep_input_df, N_input_df, 
                          MP_flag)
        
            if print_out:
                print2 = 'Starting from a nitrate leaching rate today of '\
                         '{:.1f} lb/ac per year, \nthe nitrate leaching rate '\
                         'must be reduced by {:.1f} lb/ac each year \nuntil '\
                         'reaching: '.format(rate_prior, abs(res.x[0]))
                #print(print2)
            
            if final_rate > 0:
                if print_out:
                    print3 = '\n{:.1f} lb/ac of nitrate leaching by '\
                             '{}\n'.format(final_rate, fut_date)
                    print(print2, print3)
            
            if zero_date == 'N/A':
                pass
            else:
                if print_out:
                    print3 = '\n0 lb/ac of nitrate leaching by the year {}.\n'.\
                             format(zero_date)
                    print(print2, print3)
        
        else:
            if print_out:
                print2 = 'The nitrate leaching rate does not need to be '\
                         'reduced in order to \nreach the goal concentration. '\
                         ' This realization will be plotted \nbelow using the '\
                         'current leaching rate.\n'
                print3 = ''
                print(print2)
    
    if print_out:
        print_statement = print1 + '\n' + print2 + print3
        return res.x[0], print_statement
    else:
        return res.x[0]

def opt_slope_uncert(slope_guess, user_df, N_goal, well, fut_date, 
                     sample_date, params, params_base, perc_uncert, 
                     sep_input_df, N_input_df, shift, percentile = 'med',
                     MP_flag = False, print_out = True):
    '''This function optimizes the slope by which NO3 should be decreased 
    (or increased possibly) into the future to reach a certian NO3 goal by
    a certain sample date in the future. This version of the "opt_slope" 
    function is used with the Monte Carlo realizations.
    '''  
    if print_out:
        print1 = 'In order to reach a nitrate concentration of {:.1f} mg/L '\
                 'by {}:'.format(N_goal+shift, fut_date)
        # Adding the shift amount back for consistent reporting
        print(print1)  
    
    res = minimize(future_slope_uncert, slope_guess, args = (user_df, N_goal,
                                                             well, fut_date,
                                                             sample_date, 
                                                             params, 
                                                             params_base, 
                                                             perc_uncert, 
                                                             sep_input_df, 
                                                             N_input_df, 
                                                             percentile, 
                                                             MP_flag),
                                                     method = 'nelder-mead')  
    min_N, rate_prior, N_interp_future, dates_int_future = \
                            future_constant_uncert(0, user_df, well, fut_date,
                                                   sample_date, params, 
                                                   params_base, perc_uncert, 
                                                   sep_input_df, N_input_df,
                                                   percentile, MP_flag)
    print2, print3 = '', ''
    if res.fun > 0.001:
        if print_out:
            print2 = 'The goal concentration could not be met with a steady '\
                     'decrease \nof the nitrate leaching rate. The forecasted '\
                     'concentration on \nthis date (by reducing the leaching '\
                     'rate to 0 lb/ac starting \ntoday) is {:.1f} mg/L.\n'.format(
                     round(min_N, 2))
            print(print2)            
            
    if res.fun <= 0.001:
        if res.x[0] < 0:
            sumN, zero_date, final_rate, N_interp_future, dates_int_future = \
                   future_slope_uncert_calc(res.x[0], user_df, well, fut_date,
                                            sample_date, params, params_base, 
                                            perc_uncert, sep_input_df, 
                                            N_input_df, percentile, MP_flag)
        
            if print_out:
                print2 = 'Starting from a nitrate leaching rate today of '\
                         '{:.1f} lb/ac, the \nnitrate leaching rate would '\
                         'need to be reduced by {:.1f} lb/ac \neach year until'\
                         ' reaching:'.format(rate_prior, abs(res.x[0]))
                #print(print2)
                
            if final_rate > 0:
                if print_out:
                    print3 = '\n{:.1f} lb/ac of nitrate leaching by '\
                             '{}\n'.format(final_rate, fut_date)
                    print(print2, print3)
            else:
                if print_out:
                    print3 = ''
            
            if zero_date == 'N/A':
                pass
            else:
                if print_out:
                    print3 = '\n0 lb/ac of nitrate leaching by the year {}.\n'.\
                             format(zero_date)
                    print(print2, print3)
        
        else:
            if print_out:
                print2 = 'The nitrate leaching rate does not need to be '\
                         'reduced in order to \nreach the goal concentration. '\
                         ' This realization will be plotted \nbelow using the '\
                         'current leaching rate.\n'
                print3 = ''
                print(print2)
                
    if print_out:
        print_statement = print1 + '\n' + print2 + print3
        return res.x[0], print_statement
    else:
        return res.x[0]

def future_fraction(fraction, user_df, well, fut_date, sample_date, params, 
                    sep_input_df, N_input_df, MP_flag = False):
    '''This function calculates a convolution-generated NO3 concentration at 
    a future sample date using a fraction of the NO3 leaching rate on the 
    date the NDST is run.'''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_ML(user_df, well, params, N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_MP(MP_flag, well, params, N_input_df)
        
    N_join, N_interp, dates_interp, N_total = \
               N_interpolate(user_df, well, sample_date, params, sep_input_df,
                             N_input_df, MP_flag)

    this_year = datetime.today().year
    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
              float(dat.strftime("%Y"))
    year_sample = int(np.floor(smp_dt))
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(this_year, 
                                         fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')
    N_sum_append = [N_total['N_sum'].values[-1]*fraction]*((fut_year - 
                                                            this_year))
    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df,
                      MP_flag)
    
    return sumN, N_interp_future, dates_int_future
    
def future_fraction_uncert(fraction, user_df, well, fut_date, sample_date, 
                           params, params_base, perc_uncert, sep_input_df, 
                           N_input_df, percentile = 'med', MP_flag = False):
    ''' This function calculates a convolution-generated NO3 concentration at 
    a future sample date using a fraction of the NO3 leaching rate on the date
    the NDST is run. This version of the "Future_fraction" function is used 
    with the Monte Carlo realizations.'''
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_ML(user_df, well, params, N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_MP(MP_flag, well, params, N_input_df)
        
    N_join, N_interp, dates_interp, N_total = \
               N_interpolate(user_df, well, sample_date, params, sep_input_df, 
                             N_input_df, MP_flag)

    this_year = datetime.today().year
    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
              float(dat.strftime("%Y"))
    year_sample = int(np.floor(smp_dt))
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(this_year, 
                                         fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')

    if percentile == 'max':
        N_sum_append = \
            [N_total['N_sum'].values[-1]*fraction + np.log((1+perc_uncert)**i) 
            for i in range(0,num_years)]
    if percentile == 'min':
        N_sum_append = \
            [N_total['N_sum'].values[-1]*fraction + np.log((1-perc_uncert)**i)
            for i in range(0,num_years)]
    if percentile == 'med':
        N_sum_append = \
            [N_total['N_sum'].values[-1]*fraction for i in range(0,num_years)]
        
    for i in range(0, num_years):
        if N_sum_append[i] < 0:
            N_sum_append[i] = 0
        
    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    # N_interp_future is a series.
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)  
    # sumN is a single value.
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, MP_flag)  
    
    return sumN, N_interp_future, dates_int_future

def future_frac_uncert(fraction, user_df, N_goal, well, fut_date, sample_date,
                       params, params_base, perc_uncert, sep_input_df, 
                       N_input_df, percentile = 'med', MP_flag = False):
    ''' This function calculates a convolution-generated NO3 concentration at 
    a future sample date using a fraction of the NO3 leaching rate on the date
    the NDST is run.'''
    
    if MP_flag == False:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_ML(user_df, well, params, N_input_df)
    else:
        tt, g_t, uz_tt, dt, sumPDF = \
                             age_distrib_MP(MP_flag, well, params, N_input_df)
        
    N_join, N_interp, dates_interp, N_total = \
               N_interpolate(user_df, well, sample_date, params, sep_input_df,
                             N_input_df, MP_flag)

    this_year = datetime.today().year
    dates_int_future, y2, fut_year = date_list(fut_date, tt)
    num_years = fut_year - this_year

    N_join_append = N_join[0:0]
    N_join_append = N_join_append.assign(Year = np.linspace(this_year,
                                         fut_year, num_years, dtype = int))
    N_join_append = N_join_append.set_index('Year')

    if percentile == 'max':  
        N_sum_append = \
            [N_total['N_sum'].values[-1]*fraction + np.log((1+perc_uncert)**i)
             for i in range(0,num_years)] 
    if percentile == 'min':  
        N_sum_append = \
            [N_total['N_sum'].values[-1]*fraction + np.log((1-perc_uncert)**i)
             for i in range(0,num_years)]
    if percentile == 'med':
        N_sum_append = \
            [N_total['N_sum'].values[-1]*fraction for i in range(0,num_years)]
    
    for i in range(0, num_years):
        if N_sum_append[i] < 0:
            N_sum_append[i] = 0
    N_drain_append = [N_join['Drain'].mean()]*num_years
    N_join_append = N_join_append.assign(N_sum = N_sum_append)
    N_join_append = N_join_append.assign(Drain = N_drain_append)
    N_join_future = pd.concat([N_total, N_join_append])
    N_interp_future = Y_interp(y2, N_join_future, dates_int_future)
    sumN = N_con_calc(N_interp_future, user_df, well, params, N_input_df, 
                      MP_flag)
    
    return abs(sumN - N_goal)

def opt_frac_uncert(frac_guess, user_df, N_goal, well, fut_date, sample_date,
                    params, params_base, perc_uncert, sep_input_df, 
                    N_input_df, shift, percentile = 'med', MP_flag = False, 
                    print_out = True):
    ''' This function optimizes the fraction by which NO3 leaching should be 
    applied into the future to reach a certian NO3 concentration goal by a 
    certain sample date in the future.  This function is used with the 
    Monte Carlo realizations.
    '''
    
    if print_out:
        print1 = 'In order to reduce nitrate concentration to {:.1f} mg/L by '\
                 '{}:'.format(N_goal+shift, fut_date)
        print(print1)  
    
    res = minimize(future_frac_uncert, frac_guess, 
                   args = (user_df, N_goal, well, fut_date,
                           sample_date, params, params_base, 
                           perc_uncert, sep_input_df, N_input_df, 
                           percentile, MP_flag),
                   method = 'nelder-mead')  
    min_N, rate_prior, N_interp_future, dates_int_future = \
                        future_constant_uncert(0, user_df, well, fut_date, 
                                               sample_date, params, 
                                               params_base, perc_uncert, 
                                               sep_input_df, N_input_df, 
                                               percentile, MP_flag)
    while res.x < 0:
        if min_N <= N_goal:
            frac_guess = 0
            res = minimize(future_frac_uncert, frac_guess, 
                           args = (user_df, N_goal, well, fut_date,
                                   sample_date, params, params_base, 
                                   perc_uncert, sep_input_df, N_input_df, 
                                   percentile, MP_flag),
                           method = 'nelder-mead')
        else:
            frac_guess = frac_guess/10
            res = minimize(future_frac_uncert, frac_guess, 
                           args = (user_df, N_goal, well, fut_date, 
                                   sample_date, params, params_base, 
                                   perc_uncert, sep_input_df, N_input_df, 
                                   percentile, MP_flag),
                           method = 'nelder-mead')
        
    if res.fun > 0.001:
        if print_out:
            print2 = 'The goal concentration could not be met without '\
                     'removing legacy \nnitrate from the system.  The '\
                     'forecasted nitrate concentration on \nthis date (by '\
                     'reducing the nitrate leaching rate to 0 lb/ac '\
                     '\nstarting today) is: {:.1f} mg/L. \n'.format(round(
                     min_N, 2))
            print3 = ''
            print4 = ''
            print(print2)
            
    if res.fun <= 0.001:
        rate_new = res.x[0]*rate_prior
        rate_diff = rate_prior - rate_new
        
        if rate_diff < 0:
            if print_out:
                print2 = 'The nitrate leaching rate does not need to be '\
                         'reduced in order to \nreach the goal concentration. '\
                         ' This realization will be plotted \nbelow using the '\
                         'current leaching rate. \n'
                print3 = ''
                print4 = ''
                print(print2)
            
        if rate_diff > 0:
            if print_out:
                print2 = 'The nitrate leaching rate would need to be reduced'\
                         ' by {:.0f}% from '.format(round(1 - res.x[0], 2)*100)
                print3 = '\na nitrate leaching rate of {:.1f} lb/ac to a '\
                         'rate of {:.1f} lb/ac. '.format(round(
                         rate_prior, 2), round(rate_new, 2))
                print4 = '\nThis is an absolute drop of {:.1f} lb/ac in nitrate '\
                         'leaching. \n'.format(round(rate_diff, 2))
                print(print2, print3, print4)
    
    if print_out:
        print_statement = print1 + '\n' + print2 + print3 + print4
        return res.x[0], print_statement
    else:
        return res.x[0], rate_prior

def predict_date(guess_date, N_goal, rate, user_df, well, sample_date, params,
                 sep_input_df, N_input_df, MP_flag = False):
    ''' This function outputs an absolute difference between a N_goal 
    and a convolution-generated NO3 concentration.  This NO3 
    concentration is generated using a constant input rate starting in
    2020 and continues until a future sample date, which is an input 
    parameter that is optimized in another function.
    '''
    fut_date = f'01/01/{guess_date}'
    
    sumN, rate_prior, N_interp_future, dates_int_future = future_constant(
                    rate, user_df, well, fut_date, sample_date, params, 
                    sep_input_df, N_input_df, MP_flag)
    
    return (sumN - N_goal)

def predict_date_uncert(guess_date, N_goal, rate, user_df, well, sample_date, 
                        params, params_base, perc_uncert, sep_input_df, 
                        N_input_df, percentile, MP_flag):
    ''' This function outputs a difference between a N_goal and a 
    convolution-generated NO3 concentration.  This NO3 concentration is 
    generated using a constant input rate that starts in the year that the
    NDST is run and continues until a future sample date, which is an input
    parameter that is optimized in another function.  This function is used 
    with the Monte Carlo realizations.
    '''
    fut_date = f'01/01/{guess_date}'
    
    sumN, rate_prior, N_interp_future, dates_int_future = future_constant_uncert(
                           rate, user_df, well, fut_date, sample_date, params,
                           params_base, perc_uncert, sep_input_df, N_input_df, 
                           percentile, MP_flag)
    
    return (sumN - N_goal)

def find_date(N_goal, rate, user_df, well, sample_date, guess_date, params,
              sep_input_df, N_input_df, MP_flag = False):
    '''This function calculates a list of nitrate concentrations for a 
    series of guess_years in order for another function (opt_date) to 
    find the first year at which a certain goal is reached.
    '''
    this_year = datetime.today().year
    
    num_years = (guess_date - this_year)
    years = np.linspace(this_year, guess_date, num_years, dtype = int)

    min_calc = []

    for count, guess_year in enumerate(years):
        min_calc.append(predict_date(guess_year, N_goal, rate, user_df, well,
                        sample_date, params, sep_input_df, N_input_df, 
                        MP_flag))
        
    return min_calc

def find_date_uncert(N_goal, rate, user_df, well, sample_date, guess_date, 
                     params, params_base, perc_uncert, sep_input_df, 
                     N_input_df, percentile, MP_flag = False):
    '''This function calculates a list of nitrate concentrations for 
    a series of guess_years in order for another function (opt_date) to
    find the first year at which a certain goal is reached.  This function 
    is used with the Monte Carlo realizations.
    '''
    this_year = datetime.today().year
    
    num_years = (guess_date - this_year)
    years = np.linspace(this_year, guess_date, num_years, dtype = int)

    min_calc = []

    for count, guess_year in enumerate(years):
        min_calc.append(predict_date_uncert(guess_year, N_goal, rate, user_df,
                        well, sample_date, params, params_base, perc_uncert, 
                        sep_input_df, N_input_df, percentile, MP_flag))
        
    return min_calc

def opt_date(N_goal, rate, user_df, well, sample_date, params, sep_input_df, 
             N_input_df, shift, MP_flag = False, guess_date = 2100, 
             print_out = True):
    '''This function optimizes the future date for which an N_goal 
    can be achieved at a certain NO3 leaching rate.'''
    
    min_calc = find_date(N_goal, rate, user_df, well, sample_date, guess_date, 
                         params, sep_input_df, N_input_df, MP_flag)  
    this_year = datetime.today().year
    num_years = (guess_date - this_year)
    
    print1 = ''
    print2 = ''
    
    if guess_date < 2199:
        while min(min_calc) > 0:
         
            guess_date = guess_date + 100
            num_years = (guess_date - this_year)
            if guess_date <= 2200:
                if print_out:
                    print1 = 'pushing out the future date...{}'.format(guess_date)
                    print(print1)
    
            if guess_date > 2200:
                if print_out:
                    print2 = 'The nitrate concentration of interest will not '\
                             'be met by the year 2200. \nTry a higher '\
                             'goal concentration or lower nitrate '\
                             'leaching rate.'
                    print(print2)
                opt_year = 'N/A - above'
                break
                
            min_calc = find_date(N_goal, rate, user_df, well, sample_date, 
                                 guess_date, params, sep_input_df, N_input_df,
                                 MP_flag)
    
        else:
            guess_years = np.linspace(this_year, guess_date, num_years, 
                                      dtype = int)
            
            if 0 in min_calc:
                zero_idx = np.where(min_calc == 0)[0][0]
                opt_year = int(guess_years[zero_idx])
                if print_out:
                    print2 = 'The nitrate concentration of {:.1f} mg/L will '\
                             'be reached by the \nyear {} given the nitrate '\
                             'leaching rate of {:.1f} lb/ac.'\
                             .format(N_goal+shift, opt_year, rate)
                    print(print2)

            if min(min_calc) < 0:
                
                if all(np.sign(min_calc) == -1):
                    if print_out:
                        print2 = 'The forecasted nitrate concentration is '\
                                 'below the stated \nnitrate concentration '\
                                 'for the entire future timeline.'
                        print(print2)
                    opt_year = 'N/A - below'
                
                else:
                    asign = np.sign(min_calc)
                    signchange = ((np.roll(asign, 1) - asign) != 0).astype(int)
                    signchange[0] = 0
                    idx = np.where(signchange == 1)[0][0]
                    opt_year = int(guess_years[idx])
                    if print_out:
                        print2 = 'The nitrate concentration of {:.1f} mg/L '\
                                 'will be reached by \nthe year {} given the '\
                                 'nitrate leaching rate of {:.1f} lb/ac.'\
                                 .format(N_goal+shift, opt_year, rate)
                        print(print2) 
    else:
        if print_out:
            print1 = 'The nitrate concentration of interest will not be met '\
                     'by the year 2200. \nTry a lower nitrate leaching rate '\
                     'or a higher goal concentration.'
            print(print1)
        opt_year = 'N/A - above'
    
    if print_out:
        print_statement = print1 + '\n' + print2
        return opt_year, print_statement
    else:
        return opt_year

def opt_date_uncert(N_goal, rate, user_df, well, sample_date, params, 
                    params_base, perc_uncert, sep_input_df, N_input_df,
                    shift, percentile = 'med', MP_flag = False, 
                    guess_date = 2100, print_out = True):
    '''This function optimizes the future date for which an N_goal can 
    be achieved at a certain NO3 leaching rate.  This function is used 
    with the Monte Carlo realizations.'''
       
    min_calc = find_date_uncert(N_goal, rate, user_df, well, sample_date, 
                                guess_date, params, params_base, perc_uncert,
                                sep_input_df, N_input_df, percentile, MP_flag = MP_flag)  

    this_year = datetime.today().year
    num_years = (guess_date - this_year)
    
    print1 = ''
    print2 = ''
    
    if guess_date < 2199:
        while min(min_calc) > 0:
         
            guess_date = guess_date + 100
            num_years = (guess_date - this_year)
            if guess_date <= 2200:
                if print_out:
                    print1 = 'pushing out the future date...{}'.format(guess_date)
                    print(print1)
    
            if guess_date > 2200:
                if print_out:
                    print2 = 'The nitrate concentration of interest will not '\
                             'be met by the year 2200. \nTry a lower nitrate '\
                             'leaching rate or a higher goal concentration.'
                    print(print2)
                opt_year = 'N/A - above'
                break
                
            min_calc = find_date_uncert(N_goal, rate, user_df, well, 
                                        sample_date, guess_date, params, 
                                        params_base, perc_uncert, 
                                        sep_input_df, N_input_df, percentile, 
                                        MP_flag = MP_flag)
    
        else:
            guess_years = np.linspace(this_year, guess_date, num_years,
                                      dtype = int)
     
            if 0 in min_calc:
                zero_idx = np.where(min_calc == 0)[0][0]
                opt_year = int(guess_years[zero_idx])
                if print_out:
                    print2 = 'The nitrate concentration of {:.1f} mg/L will '\
                             'be reached by the \nyear {} given the nitrate '\
                             'leaching rate of {:.1f} lb/ac.'.\
                             format(N_goal+shift, opt_year, rate)
                    print(print2)
                    
            if min(min_calc) < 0:
                
                if all(np.sign(min_calc) == -1):
                    if print_out:
                        print2 = 'The forecasted nitrate concentration is '\
                                 'below the stated \nnitrate concentration '\
                                 'for the entire future timeline.'
                        print(print2)
                    opt_year = 'N/A - below'
                
                else:
                    asign = np.sign(min_calc)
                    signchange = ((np.roll(asign, 1) - asign) != 0).astype(int)
                    signchange[0] = 0
                    idx = np.where(signchange == 1)[0][0]
                    opt_year = int(guess_years[idx])
                    if print_out:
                        print2 = 'The nitrate concentration of {:.1f} mg/L '\
                                 'will be reached by \nthe year {} given the '\
                                 'nitrate leaching rate of {:.1f} lb/ac.'\
                                 .format(N_goal+shift, opt_year, rate)
                        print(print2)
                        
    else:
        if print_out:
            print1 = 'The nitrate concentration of interest will not be met '\
                     'by the year 2200. \nTry a lower nitrate leaching rate '\
                     'or a higher goal concentration.'
            print(print1)
        opt_year = 'N/A - above'
    
    if print_out:
        print_statement = print1 + '\n' + print2
        return opt_year, print_statement
    else:
        return opt_year

def N_over_time(user_df, well, params, sep_input_df, N_input_df, 
                MP_flag = False):
    '''This function returns a list of decades and NO3 concentrations 
    for each 5-yr period from 1860 - 2020.  Future NO3 concentrations 
    are calculated later in the future_scenarios function based on what
    future scenario is chosen.
    '''
    decades = np.linspace(1860, 2020, 34, dtype = int)
    dates, N_dec = ([None]*len(decades) for i in range(2))
    for i in range(0, len(dates)):
        dates[i] = '01/01/{}'.format(decades[i])
        N_dec[i] = N_convolve(user_df, well, str(dates[i]), params, 
                              sep_input_df, N_input_df, MP_flag)

    return decades, N_dec
    
def historical_simulation(input_file, user_df, sep_input_df, N_input_df,
               user_params_mults = 'default', density_plot = True, MP_flag=False, 
               high_res=True, shift2mean=False, usermode=True, gisdir=gisdir, 
               pestdir=pestdir, rank_realz_date=datetime.today().strftime('%m/%d/%Y')):
    '''This is one of the two primary functions of the NDST.  It is accessed
    directly from the GUI by the user.  The function estimates the NO3
    concentration for the date the NDST is run, and generates graphs of
    historical nitrate leaching, age distributions, and historical NO3
    concentrations for the users' well.
    '''
    set_seed = False  
    
    default_params_mults =  {'mean_age_mult' : 1,
                      'age_dispersivity_mult': 1,
                      'uz_mobile_watercontent_mult' : 1,
                      'IBIS_mult' : 1,
                      'IBIS_start_mult' : 1,
                      'IBIS_end_mult' : 1,
                      'recharge_mult' : 1,
                      'septic_mult' : 1,
                      'k_O2_mult' : 1,
                      'O2_cut_mult' : 1,
                      'k_NO3_mult' : 1}
    
    if user_params_mults == default_params_mults:
        user_params_mults = 'default'

    if usermode == True:
    
        # Get the well name if provided in input XLSX file, else use the
        # file name (presumably matches some ID for the well).
        try:
            well_id = user_df['Well ID or well name'][0]
        except:
            well_id = os.path.splitext(os.path.basename(input_file))[0]
            
        if user_df.NO3_obs.isnull().values.all():
            # If no samples, arbitrarily decide sample date is today, 
            # which doesn't affect solutions.
            sample_date = datetime.today().strftime("%m/%d/%Y")  
            multi_sample_dates = [None]
            well = user_df.head(1).index[0]
        else:
            # Use the most recent sample date, but doesn't affect 
            # solution as ageML and dtwML used long-term average.
            sample_date = user_df.sample_dt.astype('datetime64[ns]').\
                                                   max().strftime("%m/%d/%Y")  
            well = user_df[user_df['sample_dt'] == 
                   user_df.sample_dt.max()].index[0]
            multi_sample_dates = []
            for i in user_df.index:
                
                if type(user_df.sample_dt[i]) == str:
                    dat = datetime.strptime(user_df.sample_dt[i], "%Y-%m-%d")
                else: 
                    dat = user_df.sample_dt[i]
                
                smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
                          float(dat.strftime("%Y"))
                multi_sample_dates.append(smp_dt)
        user_df_short = user_df.copy()
    else:
        well = int(input('Well number?   '))
        sample_date = datetime.strptime(user_df.loc[well, 'sample_dt'],
                                        "%Y-%m-%d").strftime('%m/%d/%Y')
        user_df_short = user_df.loc[[well]]

    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
              float(dat.strftime("%Y"))
    year = dat.year

    print('')
    
    # Write output to a log file (PDF format).
    logfilename = os.path.join(output_path,'{}_historical_simulation_{}.pdf'.\
                  format(os.path.basename(input_file).replace('.xlsx',''), 
                         datetime.now().strftime("%b%d_%H%M")))
    with PdfPages(logfilename) as pdf:    
        if usermode == True:
            if user_df.NO3_obs.isnull().values.all():
                # Use of the shift2mean option is discouraged as this type of
                # individual well adjustment can have large, unanticipated
                # effects on forecast scenario results.
                if shift2mean:
                    txt1 = 'The shift2mean option cannot be used with a \n' \
                           'well lacking measured nitrate concentration data.' \
                           '\nThe shift2mean option has been turned off.'
                    shift2mean = False
                else:
                    txt1 = 'No measured nitrate concentrations were provided.'
                print(txt1)
                txt2 = ''
            else:
                first_date = user_df.sample_dt.min()
                last_date = user_df.sample_dt.max()
                num_samples = user_df.loc[:, 'NO3_obs'].count()
                mean_N = user_df.loc[:, 'NO3_obs'].mean()
                txt1 = f'The mean nitrate concentration from {num_samples} '\
                       f'samples between {first_date:%m-%d-%Y} and '\
                       f'{last_date:%m-%d-%Y} \nis {mean_N:.1f} mg/L.'
                txt2 = ''
                print(txt1)

        else:
            txt1 = f'The sample date for well {well_id} is {sample_date}.'
            known_N = user_df.loc[well, 'NO3_obs']
            txt2 = f'The observed nitrate concentration on this date is'\
                    f'{known_N:.4f} mg/L'
            print(txt1)
            print(txt2)
            
        print('\nPlease wait: Setting up Monte Carlo uncertainty '
              'realizations....\n')

        params_base = ws.get_well_params(well, user_df)
        params_orig = params_base.copy()
        gdf = gpd.GeoDataFrame(user_df_short,
                      crs=CRS("epsg:4326"),
                      geometry=gpd.points_from_xy(user_df_short.longitude_deg,
                                                  user_df_short.latitude_deg))
        grid_pars = [
                'disp_ratio', 'uz_mobile', 'k_o2_mult',
                'age_mult', 'ibis_mult', 'is_start_mult',
                'is_end_mult', 'flux_mult', 'septic_mult',
                'o2_cut', 'k_o2_to_k_no3_mult'
                ]
        
        MC_params = build_mc_df(
                x_coord = gdf.geometry.x.values[0], y_coord = 
                          gdf.geometry.y.values[0], 
                crs=gdf.crs, 
                grid_file_path = grid_file,
                par_ens_path= par_ens_file,
                grid_pars=grid_pars, 
                grid_pars_path= grid_pars_path
                )
        params_MC_base = MC_params.loc['base'].to_dict()
        params_base.update(params_MC_base)
        params_base = ws.user_update_params(params_base, user_params_mults)
        MC_params_dict = MC_params.to_dict('records')

        max_date = int(datetime.today().year)
        if high_res == False:
            decades = np.linspace(1960, np.floor(max_date/10)*10, 
                                  int((np.floor(max_date/10)*10-1960)/10+1), 
                                  dtype = int)
            year = (year//10)*10
        else:
            decades = np.linspace(1960, (max_date), (max_date - 1959), 
                                  dtype = int)
        
        sumN_calc = [None]*len(MC_params)
        runs = np.arange(0, len(MC_params)).tolist()
        for j in range(0, len(MC_params)):
            params_change = params_orig.copy()
            params_change.update(MC_params_dict[j])
            
            sumN_i = N_convolve(user_df, well, rank_realz_date, 
                                params_change, sep_input_df, 
                                N_input_df, MP_flag)
            sumN_calc[j] = sumN_i
        
        # ID the realizations with the 5%, 50% and 95% simulated 
        # concentrations on "today's date" (date the NDST is run).
        d = {'runs' : runs, 'sumN' : sumN_calc}
        data = pd.DataFrame(d).set_index('runs')
        data_desc = data.describe(percentiles = [0.05, .5, .95])
        std = data_desc.loc['std']['sumN']
        idx5 = np.array(abs(data['sumN'].values - 
                        data_desc.loc['5%']['sumN'])).argmin()
        idx50 = np.array(abs(data['sumN'].values - 
                         data_desc.loc['50%']['sumN'])).argmin()
        idx95 = np.array(abs(data['sumN'].values - 
                         data_desc.loc['95%']['sumN'])).argmin() 
        
        params5 = params_orig.copy()
        params5.update(MC_params_dict[idx5])
        params5 = ws.user_update_params(params5, user_params_mults)
        params50 = params_orig.copy()
        params50.update(MC_params_dict[idx50])
        params50 = ws.user_update_params(params50, user_params_mults)
        params95 = params_orig.copy()
        params95.update(MC_params_dict[idx95])
        params95 = ws.user_update_params(params95, user_params_mults)

        if (user_params_mults != 'default') & (density_plot == True): #rerun with user_params_mults
            sumN_calc = [None]*len(MC_params)
            runs = np.arange(0, len(MC_params)).tolist()
            for j in range(0, len(MC_params)):
                params_change = params_orig.copy()
                params_change.update(MC_params_dict[j])
                params_change = ws.user_update_params(params_change, user_params_mults)
                
                sumN_i = N_convolve(user_df, well, rank_realz_date, 
                                    params_change, sep_input_df, 
                                    N_input_df, MP_flag)
                sumN_calc[j] = sumN_i

            d = {'runs' : runs, 'sumN' : sumN_calc}
            data = pd.DataFrame(d).set_index('runs')

        # For plotting
        if MP_flag == False:
            calc_av_age = user_df.loc[well, 'total_tt_years']
        else:
            calc_av_age = MP_flag['mean_tt']
        
        mean_tt5 = params5['age_mult']*calc_av_age
        if MP_flag == False:
            tt5, g_t5, uz_tt5, dt5, sumPDF5 = \
                            age_distrib_ML(user_df, well, params5, N_input_df)
        else:
            tt5, g_t5, uz_tt5, dt5, sumPDF5 = \
                            age_distrib_MP(MP_flag, well, params5, N_input_df)
        
        mean_tt50 = params50['age_mult']*calc_av_age
        if MP_flag == False:
            tt50, g_t50, uz_tt50, dt50, sumPDF50 = \
                           age_distrib_ML(user_df, well, params50, N_input_df)
        else:
            tt50, g_t50, uz_tt50, dt50, sumPDF50 = \
                           age_distrib_MP(MP_flag, well, params50, N_input_df)
        
        mean_tt95 = params95['age_mult']*calc_av_age
        
        if MP_flag == False:
            tt95, g_t95, uz_tt95, dt95, sumPDF95 = \
                           age_distrib_ML(user_df, well, params95, N_input_df)
        else:
            tt95, g_t95, uz_tt95, dt95, sumPDF95 = \
                           age_distrib_MP(MP_flag, well, params95, N_input_df)
        
            N_join, N_interp, dates_interp, N_total = \
                           N_interpolate(user_df, well, sample_date, 
                                         params_change, sep_input_df, 
                                         N_input_df, MP_flag)
            
        if MP_flag == False:
            tt, g_t, uz_tt, dt, sumPDF = \
                      age_distrib_ML(user_df, well, params_change, N_input_df)
            age_mult = params_change['age_mult']
            mean_tt = age_mult*(user_df.loc[well, 'total_tt_years']) 
        else:
            tt, g_t, uz_tt, dt, sumPDF = \
                      age_distrib_MP(MP_flag, well, params_change, N_input_df)
            mean_tt = MP_flag['mean_tt']
            
        thisnewyeardate = '01/01/{}'.format(int(datetime.today().year))
        N_join_5, N_interp_5, dates_interp_5, N_total_5 = \
                        N_interpolate(user_df, well, thisnewyeardate, params5, 
                                      sep_input_df, N_input_df, MP_flag)
        N_join_50, N_interp_50, dates_interp_50, N_total_50 = \
                        N_interpolate(user_df, well, thisnewyeardate, 
                                      params50, sep_input_df, N_input_df, 
                                      MP_flag)
        N_join_95, N_interp_95, dates_interp_95, N_total_95 = \
                        N_interpolate(user_df, well, thisnewyeardate, 
                                      params95, sep_input_df, N_input_df, 
                                      MP_flag)
        N_join, N_interp_base, dates_interp_base, N_total_base = \
                        N_interpolate(user_df, well, thisnewyeardate, 
                                      params_base, sep_input_df, N_input_df, 
                                      MP_flag) 
        
        dates, N_dec, N_dec1, N_dec5, N_dec50, N_dec95 = \
                                       ([None]*len(decades) for i in range(6))
        this_year = datetime.today().year
        
        for i in range(0, len(dates)):
            dates[i] = '01/01/{}'.format(decades[i])
            #N_dec is the series of computed NO3 from the N_convolve function.
            sumN_i = N_convolve(user_df, well, str(dates[i]), params_base, 
                                sep_input_df, N_input_df, MP_flag)
            N_dec[i] = sumN_i  
            age_mult = params_base['age_mult']
            if MP_flag == False:
                mean_tt_base = age_mult*(user_df.loc[well, 'total_tt_years'])   
            else:
                mean_tt_base = MP_flag['mean_tt']
            
            if MP_flag == False:
                tt_base, g_t_base, uz_tt_base, dt, sumPDF = \
                        age_distrib_ML(user_df, well, params_base, N_input_df)
            else:
                tt_base, g_t_base, uz_tt_base, dt, sumPDF = \
                        age_distrib_MP(MP_flag, well, params_base, N_input_df)
            
            # Use N_convolve function to populate historical concentrations.
            if datetime.strptime(dates[i], "%m/%d/%Y") < datetime.today():
                sumN_i2 = N_convolve(user_df, well, str(dates[i]), params5, 
                                     sep_input_df, N_input_df, MP_flag)
                sumN_i3 = N_convolve(user_df, well, str(dates[i]), params50, 
                                     sep_input_df, N_input_df, MP_flag)
                sumN_i4 = N_convolve(user_df, well, str(dates[i]), params95, 
                                     sep_input_df, N_input_df, MP_flag)
                N_dec5[i] = sumN_i2
                N_dec50[i] = sumN_i3
                N_dec95[i] = sumN_i4
    
        if shift2mean:
            last_samp_yr = \
                datetime.strptime(user_df.sample_dt.astype('datetime64[ns]').\
                                  max().strftime("%m/%d/%Y"), "%m/%d/%Y").year
            first_samp_yr = \
                datetime.strptime(user_df.sample_dt.astype('datetime64[ns]').\
                                  min().strftime("%m/%d/%Y"), "%m/%d/%Y").year
            dec_his_smpl = [i for i in decades if i <= first_samp_yr]
            dec_betw_smpl = \
                  [i for i in decades if (first_samp_yr <= i <= last_samp_yr)]
            simNO3mean_sampledur = \
                np.nanmean(N_dec[len(dec_his_smpl) - 1 : len(dec_his_smpl) + \
                           len(dec_betw_smpl) -1])
            shift = mean_N - simNO3mean_sampledur
            shift_title = "NOTE: Simulated results have \nbeen shifted to '\
                          'the mean \nof the measurements."
            
            if shift >= 0.0:
                updown = 'up'
            else:
                updown = 'down'
            txt4 = '\n \n***************************************************'\
                   '*************\nYou have selected to shift the simulated '\
                   'results to match the mean\nof measured nitrate values.  '\
                   'As a result, the nitrate concentration\ngraphs (at the '\
                   'bottom) have been shifted {} by {:.2f} mg/L. \n*********'\
                   '******************************************************'\
                   '*\n\n'.format(updown, shift)
            print(txt4)
            
        else:
            shift = np.float64(0.0)
            shift_title = ''
            txt4 = ''

        rank_realz_date = datetime.strptime(rank_realz_date, '%m/%d/%Y')
        txt5 =  f'Of the 450 total realizations, the individual realizations '\
                f'used for displaying uncertainty \nwere ranked and '\
                f'identified as the 5th, 50th, and 95th percentiles based on '\
                f'\nconcentrations simulated for: {rank_realz_date:%m-%d-%Y}.\n'
        
        if user_params_mults == 'default':
            txt7 = 'All model parameters were set to their default calibrated'\
                   ' values (no "User Interaction").'
            txt8 = ''
        else:
            txt7 = 'Model parameters were multiplied by the user supplied '\
                   'user_params_mults dictionary:\n'
            txt8 = [f'{key} : {value}' 
                    for key, value in user_params_mults.items()]
        
        firstPage = plt.figure(figsize = (8.5,11))
        firstPage.clf()
        datenow = datetime.now().strftime("%m/%d/%Y")
        timenow = datetime.now().strftime("%I:%M%p")
        firstPage.text(0.15,0.9,'This file is a log of certain GW-NDST '
             'inputs, results (graphs), \nand details about the python '
             'environment used to run the \n"cs.historical_simulation" on '
             '{} at {}.'.format(datenow, timenow),
             transform=firstPage.transFigure, size=14, linespacing = 1.25, 
             ha="left")
        firstPage.text(0.15,0.86,"\nUser's well input path and file name:\n", 
                     transform=firstPage.transFigure, size=10, linespacing = 1, 
                     ha="left")
        firstPage.text(0.55,0.86,'{}\n'.format(input_file), 
                     transform=firstPage.transFigure, size=10, linespacing = 1, 
                     ha="left")
        txt_combined = txt1 + '\n' + txt2 + '\n' + txt4 + '\n' + txt5 + \
                       '\n\n' + txt7 + '\n' + '\n'.join(txt8)
        firstPage.text(0.15,0.45,txt_combined, transform=
                       firstPage.transFigure, size=10, linespacing = 1.15, 
                       ha="left")
        
        pdf.savefig()
        plt.close()
        
        # Figure 1
        plt.figure(figsize = (8.5, 6))
        # Plot realizations first so base case is on top.
        plt.plot(dates_interp_5, N_interp_5.N_sum, color = 'cornflowerblue', alpha = 0.5, 
                 label = 'Near min (5%) realization')  # label = 0
        plt.plot(dates_interp_50, N_interp_50.N_sum, color = 'coral', 
                 label = 'Median (50%) realization') # label = 1
        plt.plot(dates_interp_95, N_interp_95.N_sum, color = 'mediumseagreen', alpha = 0.5,
                 label = 'Near max (95%) realization')  # label = 2
        plt.plot(dates_interp_base, N_interp_base.N_sum, color = 'black', 
                 label = 'Base realization')
        plt.plot(N_total_base.loc[year:this_year].N_sum, color = 'black')
        
        plt.title('Nitrate Input (lb/ac) Over Time at Well {}'.format(well_id))
        plt.xlabel('Year')
        plt.ylabel('Nitrate leached [lb/ac]')
        plt.xlim(1920, this_year)
        handles, labels = plt.gca().get_legend_handles_labels()
        order = [3,2,1,0]
        plt.legend([handles[idx] for idx in order],
                   [labels[idx] for idx in order], loc='best', 
                   fontsize='small')
        pdf.savefig()
        
        # Figure 2
        plt.figure(figsize = (8.5, 6))
        try:
            idx = np.where(tt_base > mean_tt_base*4)[0][0]
        except:
            idx = np.argmax(tt_base)
        
        plt.plot(tt5[:idx], g_t5[:idx], color = 'cornflowerblue', alpha = 0.5,
                 label = 'Near min (5%) realization; \nmean age = {:.0f} '\
                         'years'.format(mean_tt5))
        plt.plot(tt50[:idx], g_t50[:idx], color = 'coral', 
                 label = 'Median (50%) realization; \nmean age = {:.0f} '\
                         'years'.format(mean_tt50))
        plt.plot(tt95[:idx], g_t95[:idx], color = 'mediumseagreen', alpha = 0.5,
                 label = 'Near max (95%) realization; \nmean age = {:.0f} '\
                         'years'.format(mean_tt95))
        plt.plot(tt_base[:idx], g_t_base[:idx], color = 'black', 
                 label = 'Base realization; \nmean age = {:.0f} '\
                         'years'.format(mean_tt_base))
        plt.xlabel('Age in Years')
        plt.ylabel('Probability')
        plt.yticks(fontsize = 7)
        plt.title('Age Distribution at Well {}'.format(well_id))                  
        handles, labels = plt.gca().get_legend_handles_labels()
        order = [3,2,1,0]
        plt.legend([handles[idx] for idx in order],
                   [labels[idx] for idx in order], loc='best', 
                   fontsize='small')
        pdf.savefig()
        
        # Figure 3
        plt.figure(figsize = (8.5, 6))
        # Plot realizations first so base case is on top

        dec_hist = [i for i in decades if i <= this_year]

        if density_plot:

            fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (8.5, 6),
                    gridspec_kw=
                    {'width_ratios': [7, 1], 'hspace' : 0, 'wspace' : 0},
                                        tight_layout = True)
        else:
            fig, ax1 = plt.subplots(1, 1, figsize = (8.5, 6))
            
        ax1.plot(dec_hist, N_dec5[:len(dec_hist)]+shift, color = 'cornflowerblue', 
                    alpha = 0.5, label = 'Near min (5%) realization')  # label = 0
        ax1.plot(dec_hist, N_dec50[:len(dec_hist)]+shift, color = 'coral', 
                    label = 'Median (50%) realization')  # label = 2
        ax1.plot(dec_hist, N_dec95[:len(dec_hist)]+shift, 
                    color = 'mediumseagreen', alpha = 0.5,
                    label = 'Near max (95%) realization')  # label = 4 
        ax1.plot(dec_hist, N_dec[:len(dec_hist)]+shift, color = 'black', 
                    zorder=1, label = 'Base realization')  # label 1

        if usermode == True:
            #if len(multi_sample_dates) > 0:
            if not user_df.NO3_obs.isnull().values.all():
                ax1.scatter(multi_sample_dates, user_df.NO3_obs, 
                            label = 'Measured $NO_3$ conc [mg/L]', color = 'red',
                            marker = '.', zorder=2)  # label 3
                order = [3,2,1,0,4]
            else:
                order = [3,2,1,0]
        else:
            order = [3,2,1,0,4]
            ax1.scatter(smp_dt, known_N, 
                        label = 'Measured $NO_3$ conc.: {:.2f} '\
                        'mg/L'.format(known_N), color = 'mediumturquoise', 
                        marker = '*', zorder=2)
            
        ax1.set_xlabel('Year')
        ax1.set_ylabel('Nitrate concentration [mg/L]')
        ax1.set_xlim(1960, this_year)
        try:  # 95th is highest of realz
            ymax = np.max([np.max(N_dec95[:len(dec_hist)])*1.25, 
                    np.nanmax(user_df.NO3_obs.values)*1.1])  
        except:
            ymax = np.max(N_dec95[:len(dec_hist)])*1.25
        ax1.set_ylim(0, ymax)
        ax1.set_xticks(np.arange(1960, 2030, 10), np.arange(1960, 2030, 10))

        # List for the order of labels in the legend specified above, 
        # as it depends on if there are samples.

        fig.suptitle('Nitrate Concentration Over Time at Well {}'.format(well_id))         
        handles, labels = ax1.get_legend_handles_labels()
        handles_list = [handles[idx] for idx in order]
        labels_list = [labels[idx] for idx in order]

        if density_plot:

            ax1.set_xlim(1960, this_year)

            bins = ax2.hist(data, bins = 25, orientation = 'horizontal', 
                color = 'grey', 
                label = f'All realizations on {rank_realz_date:%m-%d-%y}')
            ax2.set_xlim(0,np.max(bins[0])*1.25)
            ax2.set_ylim(0, ymax)
            ax2.set_xticklabels([])
            ax2.set_xticks([])
            ax2.set_yticklabels([])
            ax2.set_yticks([])
            handles2, labels2 = ax2.get_legend_handles_labels()
            ax1.legend(np.append(handles_list, handles2),
                    np.append(labels_list, labels2), loc='upper left', 
                    fontsize='small', framealpha=0.4, title=shift_title)

        else:
            ax1.legend(handles_list, labels_list, loc='upper left', 
                fontsize='small', framealpha=0.4, title=shift_title)

        pdf.savefig()
        
        LogPage = plt.figure(figsize = (8.5,11))
        LogPage.clf()
        
        installed_packages = pkg_resources.working_set
        installed_packages_list = sorted(["%s==%s" % (i.key, i.version)
                                            for i in installed_packages])
        
        LogPage.text(0.15,0.92,'Python packages and versions installed in '
                     'the running environment:', 
                     transform=LogPage.transFigure,linespacing = 1 ,size=8, 
                     ha="left")
        LogPage.text(0.15,0.025,
                     '\n'.join(installed_packages_list
                               [:int(len(installed_packages_list)/2)]), 
                               transform=LogPage.transFigure, size=8, 
                               linespacing = 1, ha="left")
        LogPage.text(0.5,0.025,
                     '\n'.join(installed_packages_list
                               [int(len(installed_packages_list)/2):]), 
                               transform=LogPage.transFigure, size=8, 
                               linespacing = 1, ha="left")
        pdf.savefig()
        print('These results have been saved to {}'.format(logfilename))
        plt.close()
                  
def run_futures(x, var1, var2, user_df, well, sample_date, params, 
                params_base, perc_uncert, sep_input_df, N_input_df, 
                high_res, shift, percentile, density_plot = False, 
                MP_flag = False, print_out = True):
    '''This is a "helper" function for the MC_future function.
    '''
    cal_print = 'For the base realization with zero uncertainty for future '\
              'leaching:\n'
    
    if x == 1:
        fraction = 1
        fut_date = var1
        sumN, N_interp_future, dates_int_future = \
        future_fraction_uncert(fraction, user_df, well, fut_date, sample_date,
                               params, params_base, perc_uncert, sep_input_df, 
                               N_input_df, percentile, MP_flag = MP_flag)
    if x == 2:
        rate = var1
        fut_date = var2
        sumN, rate_2016, N_interp_future, dates_int_future = \
        future_constant_uncert(rate, user_df, well, fut_date, sample_date, 
                               params, params_base, perc_uncert, sep_input_df,
                               N_input_df, percentile, MP_flag = MP_flag)
    if x == 3:
        fraction = var1
        fut_date = var2
        sumN, N_interp_future, dates_int_future = \
        future_fraction_uncert(fraction, user_df, well, fut_date, sample_date, 
                               params, params_base, perc_uncert, sep_input_df, 
                               N_input_df, percentile, MP_flag = MP_flag)
    if x == 4:
        
        frac_guess = 1
        N_goal = var1
        fut_date = var2
        if print_out:
            print(cal_print)
            extra_var1, extra_var2 = fraction, \
            print_statement = opt_frac_uncert(frac_guess, user_df, N_goal, well, 
                                       fut_date, sample_date, params, params_base,
                                       perc_uncert, sep_input_df, N_input_df, shift, 
                                       percentile, MP_flag, print_out = print_out)
            extra_var2 = cal_print + '\n' + extra_var2 
        else:
            extra_var1, extra_var2 = fraction, rate_prior = opt_frac_uncert(
                                            frac_guess, user_df, N_goal, 
                                             well, fut_date, sample_date, 
                                             params, params_base, perc_uncert,
                                             sep_input_df, N_input_df,
                                             shift, percentile, MP_flag, 
                                             print_out = print_out)
        if fraction > 1.0:
            fraction = 1.0  
        sumN, N_interp_future, dates_int_future = future_fraction_uncert(fraction, 
                                                  user_df, well, fut_date, 
                                                  sample_date, params, params_base,
                                                  perc_uncert, sep_input_df, N_input_df, 
                                                  percentile, MP_flag)
                                                         
    if x == 5:
        
        slope_guess = 0
        N_goal = var1
        fut_date = var2
        if print_out:
            print(cal_print)
            extra_var1, extra_var2 = slope, \
            print_statement = opt_slope_uncert(slope_guess, user_df, N_goal, well, 
                                        fut_date, sample_date, params, params_base,
                                        perc_uncert, sep_input_df, N_input_df, shift, 
                                        percentile, MP_flag, print_out = print_out)
            extra_var2 = cal_print + '\n' + extra_var2
        else:
            extra_vars = slope = opt_slope_uncert(slope_guess, user_df, N_goal, well,
                                           fut_date, sample_date, params, params_base,
                                           perc_uncert, sep_input_df, N_input_df, shift, 
                                           percentile, MP_flag, print_out = print_out)
        # Zero slope (>0 would be increasing leaching; 
        # <0 is decreasing leaching)
        if slope > 0.0:  
            slope = 0.0   
        sumN, zero_date, final_rate, N_interp_future, dates_int_future = \
        future_slope_uncert_calc(slope, user_df, well, fut_date, sample_date, params, 
                          params_base, perc_uncert, sep_input_df, N_input_df, percentile, MP_flag)
        
    if x == 6:
        
        N_goal = var1
        rate = var2
        if print_out:
            print(cal_print)
            extra_var1, extra_var2 = fut_year, \
            print_statement = opt_date_uncert(N_goal, rate, user_df, well, 
                                       sample_date, params, params_base, perc_uncert,
                                       sep_input_df, N_input_df, shift, 
                                       percentile, MP_flag, 
                                       guess_date = 2100, 
                                       print_out = print_out)
            extra_var2 = cal_print + '\n' + extra_var2
        else:
            extra_vars = fut_year = opt_date_uncert(N_goal, rate, user_df, well, 
                                             sample_date, params, params_base, perc_uncert,
                                             sep_input_df, N_input_df, shift, 
                                             percentile, MP_flag, guess_date = 2100, 
                                             print_out = print_out)
        if fut_year == 'N/A - above' or fut_year == 'N/A - below':
            fut_year = 2100
        sumN, rate_prior, N_interp_future, \
        dates_int_future = future_constant_uncert(rate, user_df, well, 
                                           '01/01/{}'.format(int(fut_year)),
                                           sample_date, params, params_base, perc_uncert,
                                           sep_input_df, N_input_df, percentile, MP_flag)
    
    max_date = int(max(dates_int_future))
    if high_res == False:
        decades = np.linspace(1960, np.floor(max_date/10 + 1)*10, 
                              int((np.floor(max_date/10 + 1)*10-1960)/10+1),
                              dtype = int)
    else:
        decades = np.linspace(1960, (max_date), (max_date - 1959), 
                              dtype = int)
    dates, N_dec = ([None]*len(decades) for i in range(2))
    
    for i in range(0, len(dates)):  
        dates[i] = '01/01/{}'.format(decades[i])
    
        if datetime.strptime(dates[i], "%m/%d/%Y") < datetime.today():
            sumN_i = N_convolve(user_df, well, str(dates[i]), params, 
                                sep_input_df, N_input_df, MP_flag)
            N_dec[i] = sumN_i
        else:
            if x in [1, 3]:
                sumN_i, N_interp_future_x, dates_int_future_x = \
                future_fraction_uncert(fraction, user_df, well, dates[i], 
                                       sample_date, params, params_base, 
                                       perc_uncert, sep_input_df, N_input_df, 
                                       percentile, MP_flag = MP_flag)
            if x == 4:
                sumN_i, N_interp_future_x, dates_int_future_x = \
                future_fraction_uncert(fraction, user_df, well, dates[i], 
                                sample_date, params, params_base, perc_uncert, 
                                sep_input_df, N_input_df, percentile, MP_flag)
            if x == 2:
                sumN_i, rate_2016_x, N_interp_future_x, dates_int_future_x = \
                future_constant_uncert(rate, user_df, well, dates[i], 
                                       sample_date, params, params_base, 
                                       perc_uncert, sep_input_df, N_input_df, 
                                       percentile, MP_flag = MP_flag)
            if x == 6:
                sumN_i, rate_2016_x, N_interp_future_x, dates_int_future_x = \
                future_constant_uncert(rate, user_df, well, dates[i], sample_date, 
                                params, params_base, perc_uncert, sep_input_df, 
                                N_input_df, percentile, MP_flag)
            if x == 5:
                sumN_i, zero_date_x, final_rate_x, N_interp_future_x, \
                dates_int_future_x = future_slope_uncert_calc(slope, user_df, well, 
                                                       dates[i], sample_date, 
                                                       params, params_base, perc_uncert, 
                                                       sep_input_df, N_input_df, percentile, MP_flag)
            # N_dec is a full series of concentrations (the dates loop).
            N_dec[i] = sumN_i  
    
    if x in [1, 2, 3]:
        if print_out:
            extra_var1 = None
            extra_var2 = ''
            return N_dec, decades, N_interp_future, dates_int_future, sumN, \
                   extra_var1, extra_var2
        else:
            extra_vars = None
            return N_dec, decades, N_interp_future, dates_int_future, sumN, \
                   extra_vars
    else:
        if print_out:
            return N_dec, decades, N_interp_future, dates_int_future, \
                   N_goal, extra_var1, extra_var2
        elif x == 4:
            if density_plot:
                return N_dec, decades, N_interp_future, dates_int_future, \
                   N_goal, extra_var1, extra_var2, sumN
            else:
                return N_dec, decades, N_interp_future, dates_int_future, \
                   N_goal, extra_var1, extra_var2
        elif x == 5:
            if density_plot:
                return N_dec, decades, N_interp_future, dates_int_future, \
                   N_goal, extra_vars, sumN
            else:    
                return N_dec, decades, N_interp_future, dates_int_future, \
                   N_goal, extra_vars
        else:
            return N_dec, decades, N_interp_future, dates_int_future, \
                   N_goal, extra_vars
    
def run_ensemble(MC_params_plus, x, var1, var2, user_df, well, sample_date, params_orig,
                params_base, perc_uncert, sep_input_df, N_input_df, 
                high_res, shift, user_params_mults = 'default', MP_flag = False):
    
    n_reals = len(MC_params_plus)
    sumN_calc = [None]*n_reals
    other_data = [None]*n_reals
    runs = np.arange(0, n_reals).tolist()
    MC_params = MC_params_plus.copy().drop(columns = ['sumN', 'outliers'])
    MC_params_dict = MC_params.to_dict('records')
    count = 0
    for j in MC_params_plus.index:
        params_change = params_orig.copy()
        params_change.update(MC_params_dict[count])
        if user_params_mults != 'default':
            params_change = ws.user_update_params(params_change, user_params_mults)
        percentile = MC_params_plus.loc[j, 'outliers']
        
        if not count%25:
            print(f'running Ensemble member {count}...')

        if x in [1, 2, 3]:

            _, _, N_interp_future, dates_int_future, sumN, _ = run_futures(x, var1, var2, user_df, well, sample_date, params_change, 
                params_base, perc_uncert, sep_input_df, N_input_df, 
                high_res, shift, percentile, density_plot = True, MP_flag = MP_flag, print_out = False)
            
            sumN_calc[count] = sumN #keep the ending N concentration to add to the plots
            other_data[count] = N_interp_future.loc[np.max(dates_int_future)].N_sum
        elif x == 4:

            _, _, _, _, _, extra_var1, extra_var2, sumN = run_futures(x, var1, var2, user_df, well, sample_date, 
                    params_change, params_base, perc_uncert, sep_input_df, N_input_df, 
                    high_res, shift, percentile, density_plot = True, MP_flag = MP_flag, print_out = False)
            
            sumN_calc[count] = sumN
            new_rate = extra_var1*extra_var2 #fraction * old_rate
            new_rate = np.clip(new_rate, 0, 100)
            # new rate can't go above 100, or below 0
            # we can change this to a higher value, as leaching 
            # above 100 is totally possible. maybe 200 max?

            other_data[count] = new_rate #multiply fraction by previous rate            

        elif x == 5:

            _, _, _, _, _, extra_vars, sumN = run_futures(x, var1, var2, user_df, well, sample_date, 
                    params_change, params_base, perc_uncert, sep_input_df, N_input_df, 
                    high_res, shift, percentile, density_plot = True, MP_flag = MP_flag, print_out = False)
            
            sumN_calc[count] = sumN
            new_rate = extra_vars
            new_rate = np.clip(new_rate, 0, 100)
            other_data[count] = new_rate #keep the variable of interest (rate, slope, or date) to plot

        else: #scenario 6

            _, _, _, _, _, extra_vars = run_futures(x, var1, var2, user_df, well, sample_date, 
                      params_change, params_base, perc_uncert, sep_input_df, N_input_df, 
                      high_res, shift, percentile, density_plot = True, MP_flag = MP_flag, print_out = False)
            sumN_calc[count] = None
            if extra_vars == 'N/A - above' or extra_vars == 'N/A - below':
                extra_vars = None
            other_data[count] = extra_vars # this is the future year
    
        count = count + 1

    d = {'runs' : runs, 'sumN' : sumN_calc, 'other_data' : other_data}
    data = pd.DataFrame(d).set_index('runs')

    return data

def future_scenarios(input_file, user_df, sep_input_df, N_input_df,  
              user_params_mults='default', density_plot = False, MP_flag = False, 
              high_res = True, shift2mean=False, usermode=True, gisdir=gisdir, 
              pestdir=pestdir, rank_realz_date=datetime.today().strftime('%m/%d/%Y')):  
    '''This is one of the two primary functions of the NDST.  It is accessed
    directly from the GUI by the user.  The function includes six forecasting
    scenarios that the user can select among, enter goal-specific information,
    and then assess the estimated nitrate concentrations or nitrate leaching 
    rate results.  All results incorporate uncertainty bounds tied to parameter
    ranges that are informed from a state-wide calibration.  The bounds are
    represented by the 5th and 95th percentile of the computed concentration 
    in the user's well on the date the tool is run from all Monte Carlo 
    realizations.  
    '''
    set_seed = False  
    print_out = False

    default_params_mults =  {'mean_age_mult' : 1,
                      'age_dispersivity_mult': 1,
                      'uz_mobile_watercontent_mult' : 1,
                      'IBIS_mult' : 1,
                      'IBIS_start_mult' : 1,
                      'IBIS_end_mult' : 1,
                      'recharge_mult' : 1,
                      'septic_mult' : 1,
                      'k_O2_mult' : 1,
                      'O2_cut_mult' : 1,
                      'k_NO3_mult' : 1}
    
    if user_params_mults == default_params_mults:
        user_params_mults = 'default'

    if usermode == True:
        
        # Get the well name if provided in input XLSX file, else use the
        # file name (presumably matches some ID for the well). If both\n
        try:
            well_id = user_df['Well ID or well name'][0]
        except:
            well_id = os.path.splitext(os.path.basename(input_file))[0]
            
        #if user_df.sample_dt.isnull().values.all():
        if user_df.NO3_obs.isnull().values.all():
            sample_date = datetime.today().strftime("%m/%d/%Y")
            multi_sample_dates = [None]
            well = user_df.head(1).index[0]
        else:   
            sample_date = user_df.sample_dt.astype('datetime64[ns]').max()\
                          .strftime("%m/%d/%Y")
            well = user_df[user_df['sample_dt'] == 
                   user_df.sample_dt.max()].index[0]
            multi_sample_dates = []
            for i in user_df.index:
            
                if type(user_df.sample_dt[i]) == str:
                    dat = datetime.strptime(user_df.sample_dt[i], "%Y-%m-%d")
                else: 
                    dat = user_df.sample_dt[i]
                    
                smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
                          float(dat.strftime("%Y"))
                multi_sample_dates.append(smp_dt)
        user_df_short = user_df.copy()
    else:  
        well = int(input('Well number?   '))
        sample_date = datetime.strptime(user_df.loc[well, 'sample_dt'], 
                      "%Y-%m-%d").strftime('%m/%d/%Y')
        user_df_short = user_df.loc[[well]]

    dat = datetime.strptime(sample_date, "%m/%d/%Y")
    smp_dt = (float(dat.strftime("%j"))-1) / 365.25 + \
              float(dat.strftime("%Y"))
    year = dat.year
    
    logfilename = os.path.join(output_path,'{}_future_scenario_{}.pdf'.\
                  format(os.path.basename(input_file).replace('.xlsx',''), 
                         datetime.now().strftime("%b%d_%H%M")))
    with PdfPages(logfilename) as pdf:   
        
        print('\n')
        if usermode == True:
            if user_df.NO3_obs.isnull().values.all():
                # Use of the shift2mean option is discouraged as this type of
                # individual well adjustment can have large, unanticipated
                # effects on forecast scenario results.            
                if shift2mean:
                    txt1 = 'The shift2mean option cannot be used with a \n' \
                           'well lacking measured nitrate concentration data.'\
                           '\nThe shift2mean option has been turned off.'
                    shift2mean = False
                else:
                    txt1 = 'No measured nitrate concentrations were provided.'
                txt2 = ''
                print(txt1)
            else:
                first_date = user_df.sample_dt.min()
                last_date = user_df.sample_dt.max()
                num_samples = user_df.loc[:, 'NO3_obs'].count()
                mean_N = user_df.loc[:, 'NO3_obs'].mean()
                txt1 = f'The mean nitrate concentration from {num_samples} '\
                       f'samples between {first_date:%m-%d-%Y} and '\
                       f'{last_date:%m-%d-%Y} \nis {mean_N:.1f} mg/L.'
                txt2 = ''
                print(txt1) 
        
        else:
            txt1 = f'The sample date for well {well} is {sample_date}.'
            known_N = user_df.loc[well, 'NO3_obs']
            txt2 = f'The observed nitrate concentration on this date is '\
                   f'{known_N:.4f} mg/L.\n'
            print(txt1)
            print(txt2)
        
        print('\nPlease wait:  Setting up scenario options and Monte '\
              'Carlo \nuncertainty realizations....')
        
        params_base = ws.get_well_params(well, user_df)
        params_orig = params_base.copy()
        
        gdf = gpd.GeoDataFrame(user_df_short,
                           crs=CRS("epsg:4326"),
                           geometry=gpd.points_from_xy
                                    (user_df_short.longitude_deg,
                                     user_df_short.latitude_deg))
        grid_pars = [
                'disp_ratio', 'uz_mobile', 'k_o2_mult',
                'age_mult', 'ibis_mult', 'is_start_mult',
                'is_end_mult', 'flux_mult', 'septic_mult',
                'o2_cut', 'k_o2_to_k_no3_mult'
                ]
        
        MC_params = build_mc_df(
                x_coord= gdf.geometry.x.values[0], 
                y_coord = gdf.geometry.y.values[0], 
                crs=gdf.crs, 
                grid_file_path = grid_file,
                par_ens_path= par_ens_file,
                grid_pars=grid_pars, 
                grid_pars_path= grid_pars_path
                )
        params_MC_base = MC_params.loc['base'].to_dict()
        params_base.update(params_MC_base)
        params_base = ws.user_update_params(params_base, user_params_mults)
        MC_params_dict = MC_params.to_dict('records')
        
        # Get initial input (leached nitrate)
        N_join_base, N_interp_base, dates_interp_base, N_total_base = \
            N_interpolate(user_df, well, sample_date, params_base, 
                                     sep_input_df, N_input_df, MP_flag)  
         
        # Get initial results for the base case,  
        # Then calculate the shift to match measured values
        max_date = int(datetime.today().year)
        if high_res == False:
            decades = np.linspace(1960, np.floor(max_date/10)*10, 
                                  int((np.floor(max_date/10)*10-1960)/10+1), 
                                  dtype = int)
            year = (year//10)*10
        else:
            decades = np.linspace(1960, (max_date), (max_date - 1959), 
                                  dtype = int)
        dates, N_dec = ([None]*len(decades) for i in range(2))
        for i in range(0, len(dates)):
            dates[i] = '01/01/{}'.format(decades[i])
            sumN_i = N_convolve(user_df, well, str(dates[i]), params_base, 
                                sep_input_df, N_input_df, MP_flag)                  
            N_dec[i] = sumN_i  
        
        if shift2mean:
            last_samp_yr = datetime.strptime(user_df.sample_dt
                           .astype('datetime64[ns]').max()
                           .strftime("%m/%d/%Y"), "%m/%d/%Y").year
            first_samp_yr = datetime.strptime(user_df.sample_dt
                            .astype('datetime64[ns]').min()
                            .strftime("%m/%d/%Y"), "%m/%d/%Y").year
            dec_his_smpl = [i for i in decades if i <= first_samp_yr]
            dec_betw_smpl = [i for i in decades 
                             if (first_samp_yr <= i <= last_samp_yr)]
            simNO3mean_sampledur = np.nanmean(N_dec[len(dec_his_smpl) - 1 : 
                                   len(dec_his_smpl) + len(dec_betw_smpl) -1])
            shift = mean_N - simNO3mean_sampledur
            shift_title = 'NOTE: Simulated results have \nbeen shifted to '\
                          'the mean \nof the measurements.'  # note in fig 3
        else:
            shift = np.float64(0.0)       
            shift_title=None
            
        # Determine the scenario
        print('')
        print('Choose which scenario you would like to run:')
        print('')
        print('1: With no changes to the current leaching rate, the nitrate '
              'concentration \n   will be ?? mg/L by __ date.')
        print('2: At a leaching rate of __ lb/ac per year, the nitrate '
              'concentration \n   will be ?? mg/L by __ date.')
        print('3: At a leaching rate of __% of current nitrate leaching, the '\
              'nitrate \n   concentration will be ?? mg/L by __ date.')
        print('4: In order to reduce nitrate concentrations to __ mg/L by __ '\
              'date, nitrate \n   leaching would need to be reduced by ?? % '\
              'starting today.')
        print('5: In order to reduce nitrate concentrations to __ mg/L by __ '\
              'date, nitrate \n   leaching would need to be reduced by ?? '\
              'lb/ac each year.')
        print('6: At a leaching rate of __ lb/ac per year, the __ mg/L '\
              'nitrate concentration \n   will be reached by ?? year.')
        print('')
        
        x = int(input('Which scenario number?  '))
        txtx = f'Scenario {x} was chosen for this run.'
            
        if x == 1:
            var1 = fut_date = str(input('\nWhat is your future planning date?'
                                        ' (must be after today) \n'
                                        '(format: MM/DD/YYYY)  '))
            var2 = 0
            txtvar1 = f'Your future planning date: {var1}.\n'
            txtvar2 = ''
        if x == 2:
            var1 = rate = float(input('\nWhat is your planned nitrate '
                                      'leaching rate (lb/ac per year)?  '))
            var2 = fut_date = str(input('\nWhat is your future planning date?'
                                        ' (must be after today) \n'
                                        '(format: MM/DD/YYYY)  '))
            txtvar1 = f'Your planned future nitrate leaching rate: {var1} '\
                        'lb/ac per year.\n'
            txtvar2 = f'Your future planning date: {var2}.\n'
        if x == 3:
            var1 = fraction = float(input('\nWhat percent (an integer, '
                                          'presumably <100) of current nitrate '
                                          'leaching are you planning?  '))
            # Convert to fraction
            var1 = var1 / 100  
            var2 = fut_date = str(input('\nWhat is your future planning date?'
                                        ' (must be after today) \n'
                                        '(format: MM/DD/YYYY)  '))
            txtvar1 = f'Your planned future nitrate leaching: {var1 * 100}% of '\
                       'current leaching rate.\n'
            txtvar2 = f'Your puture planning date: {var2}.\n'
        if x == 4:
            var1 = N_goal = float(input('\nWhat is your goal nitrate '
                                        'concentration (mg/L)?  '))
            var2 = fut_date = str(input('\nWhat is your goal date to reach '
                                        'this nitrate concentration? \n'
                                        '(must be after today) '
                                        '(format: MM/DD/YYYY)  '))
            txtvar1 = f'Your goal nitrate concentration: {var1} mg/L.\n'
            txtvar2 = f'Your future goal date: {var2}.\n'
        if x == 5:
            var1 = N_goal = float(input('\nWhat is your goal nitrate '
                                        'concentration (mg/L)?  '))
            var2 = fut_date = str(input('\nWhat is your goal date to reach '
                                        'this nitrate concentration? \n'
                                        '(must be after today) '
                                        '(format: MM/DD/YYYY)  '))
            txtvar1 = f'Your goal nitrate concentration: {var1} mg/L.\n'
            txtvar2 = f'Your future goal date: {var2}.\n'
        if x == 6:
            var1 = N_goal = float(input('\nWhat is your nitrate concentration '\
                                        'of interest (mg/L)?  '))
            var2 = rate = float(input('\nWhat is your planned nitrate leaching '
                                      'rate (lb/ac per year)?  '))
            txtvar1 = f'Your goal nitrate concentration: {var1} mg/L.\n'
            txtvar2 = f'Your planned nitrate leaching rate: {var2} lb/ac '\
                        'per year.\n'
        
        # User enters in units of percent; code converts to fraction 
        # (decimal).
        perc_uncert = float(input("\nAt what percentage should uncertainty in"
                                  " FUTURE nitrate leaching rates \nexpand "
                                  "per year (must be between 0 and 100)?\n"
                                  "This increases future leaching rates for "
                                  "realizations at or above the 95th \npercentile, "
                                  "decreases future leaching rates for realizations "
                                  "at or below \nthe 5th percentile, and has no "
                                  "effect on realizations in between.\n"
                                  "Enter zero (0) if you do not wish to increase "
                                  "uncertainty beyond what's \nalready represented "
                                  "by the Monte Carlo realizations.  "))
        perc_uncert = np.clip(np.array(perc_uncert), 0, 100) / 100
        txtuncert = f'Your uncertainty about future leaching rates: {perc_uncert*100}%.'
        
        # Shift the goal concentration.  This DEFINATELY modifies
        # the results vs non-shifted results, thus, it's not encouraged.
        if shift2mean:
            if x in [4, 5, 6]:
                var1 = N_goal = N_goal - shift
                if N_goal <= 0.0:
                    print('\nERROR.  When setting "shift2mean=True", please '
                          'ensure the \n'
                          'goal concentration minus the required shift '
                          '(run MC_current) \n'
                          'is not a negative value. \n'
                          '\nSTOPPING!  Please try again with a modified goal'
                          ' value\n'
                          'that is at least as large as the shift value '
                          'printed by\nthe MC_current code block above.')
                    sys.exit()
        
        print('\nRunning.....')
        sumN_calc = [None]*len(MC_params)
        runs = np.arange(0, len(MC_params)).tolist()
        for j in range(0, len(MC_params)):
            params_change = params_orig.copy()
            params_change.update(MC_params_dict[j])

            sumN_i = N_convolve(user_df, well, rank_realz_date, params_change, 
                                sep_input_df, N_input_df, MP_flag)
            sumN_calc[j] = sumN_i
        
        # ID the realizations with the 5, 50 and 95 simulated 
        # concentrations on today's date.
        d = {'runs' : runs, 'sumN' : sumN_calc}
        data = pd.DataFrame(d).set_index('runs')
        
        data_desc = data.describe(percentiles = [0.05, .5, .95])
        MC_params_plus = MC_params.copy()
        MC_params_plus['sumN'] = data.sumN.values
        outliers = [None]*len(MC_params)
        for i, j in enumerate(MC_params_plus.sumN.values):
            if j >= data_desc.loc['95%']['sumN']:
                outliers[i] = 'max'
            elif j <= data_desc.loc['5%']['sumN']:
                outliers[i] = 'min'
            else:
                outliers[i] = 'med'
        MC_params_plus['outliers'] = outliers

        idx5 = np.array(abs(data['sumN'].values - \
               data_desc.loc['5%']['sumN'])).argmin()
        idx50 = np.array(abs(data['sumN'].values - \
                data_desc.loc['50%']['sumN'])).argmin()
        idx95 = np.array(abs(data['sumN'].values - \
                data_desc.loc['95%']['sumN'])).argmin() 
        
        params5 = params_orig.copy()
        params5.update(MC_params_dict[idx5])
        params5 = ws.user_update_params(params5, user_params_mults)
        params50 = params_orig.copy()
        params50.update(MC_params_dict[idx50])
        params50 = ws.user_update_params(params50, user_params_mults)
        params95 = params_orig.copy()
        params95.update(MC_params_dict[idx95])
        params95 = ws.user_update_params(params95, user_params_mults)

        # For plotting
        if MP_flag == False:
            calc_av_age = user_df.loc[well, 'total_tt_years']
        else:
            calc_av_age = MP_flag['mean_tt']
        
        mean_tt5 = params5['age_mult']*calc_av_age
        if MP_flag == False:
            tt5, g_t5, uz_tt5, dt5, sumPDF5 = \
                            age_distrib_ML(user_df, well, params5, N_input_df)
        else:
            tt5, g_t5, uz_tt5, dt5, sumPDF5 = \
                            age_distrib_MP(MP_flag, well, params5, N_input_df)
        
        mean_tt50 = params50['age_mult']*calc_av_age
        if MP_flag == False:
            tt50, g_t50, uz_tt50, dt50, sumPDF50 = \
                           age_distrib_ML(user_df, well, params50, N_input_df)
        else:
            tt50, g_t50, uz_tt50, dt50, sumPDF50 = \
                           age_distrib_MP(MP_flag, well, params50, N_input_df)
        
        mean_tt95 = params95['age_mult']*calc_av_age
        if MP_flag == False:
            tt95, g_t95, uz_tt95, dt95, sumPDF95 = \
                           age_distrib_ML(user_df, well, params95, N_input_df)
        else:
            tt95, g_t95, uz_tt95, dt95, sumPDF95 = \
                           age_distrib_MP(MP_flag, well, params95, N_input_df)
                
        #######################
        ## Print out results ##
        #######################
        
        print('')
        txtres1 = '---------------------------------------------------------'\
                  '----------'
        txtres2 = '                              Results                     '
        txtres3 = '---------------------------------------------------------'\
                  '----------'
        print(txtres1)
        print(txtres2)
        print(txtres3)
        print('')
          
        age_mult = params_base['age_mult']
        if MP_flag == False:
            calc_av_age = user_df.loc[well, 'total_tt_years']
        else:
            calc_av_age = MP_flag['mean_tt']
        mean_tt_base = age_mult*calc_av_age 
        if MP_flag == False:
            tt_base, g_t_base, uz_tt, dt, sumPDF = \
                        age_distrib_ML(user_df, well, params_base, N_input_df)
        else:
            tt_base, g_t_base, uz_tt, dt, sumPDF = \
                        age_distrib_MP(MP_flag, well, params_base, N_input_df)
        
        scen_run_time = time.time()    
        N_dec_base, decades_base, N_interp_future_base, dates_int_future_base,\
            N_return_base, extra_var1_base, extra_var2_base = run_futures(x, 
            var1, var2, user_df, well, sample_date, params_base, params_base, 
            perc_uncert, sep_input_df, N_input_df, high_res, density_plot = False,
            shift = shift, percentile = 'med', MP_flag = MP_flag, print_out = True)
        scen_run_tot = time.time() - scen_run_time
        ens_mins = (scen_run_tot * len(MC_params))/(60)
        if density_plot:
            print(f'\n********************** RUNTIME WARNING ********************** \n'\
                f'The base realization took {scen_run_tot:.0f} seconds to run. The '\
                f'estimated \ntime to run all {len(MC_params)} realizations is '\
                f'{ens_mins:.0f} minutes. Please be \npatient (or click the '\
                f'"interrupt kernel" option near the \ntop of the screen).\n'\
                f'*************************************************************\n')
        
        if x == 1:
            fraction = 1
            fut_date = var1
            result1 = 'With future leaching rates equal to 2020 rates, the '\
                      'nitrate concentration \nfrom the base realization is '\
                      'expected to be {:.0f} mg/L on {}.'\
                      .format(N_return_base, fut_date)
            result2 = '\n-----\nUncertainty for scenario 1 is illustrated via'\
                      ' 3 Monte Carlo realizations \nthat represent: \nthe '\
                      'near-minimum (5%) forecasted nitrate concentration as of '\
                      '{0},\nthe median (50%) forecasted nitrate concentration '\
                      'as of {0}, and \nthe near-maximum (95%) forecasted '\
                      'nitrate concentration on {0}, \nas '\
                      'follows:'.format(rank_realz_date)
            result3 = '\n--\nFor the near-minimum (5%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year reduction in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result1)
            print(result2) 
            print(result3)
            print('')
            sumN5, N_interp_future5, dates_int_future5 = \
                                            future_fraction_uncert(fraction,
                                            user_df, well, fut_date, 
                                            sample_date, params5, params_base,
                                            perc_uncert, sep_input_df, 
                                            N_input_df, percentile = 'min',
                                            MP_flag = MP_flag)
            
            result4 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {}'.format(sumN5, fut_date)
            print(result4)
            
            result5 = '\n--\nFor the median (50%) realization, with zero '\
                      'uncertainty for \nfuture leaching:'
            print(result5)
            print('') 
            sumN50, N_interp_future50, dates_int_future50 = \
                                              future_fraction_uncert(fraction,
                                              user_df, well, fut_date, 
                                              sample_date, params50, 
                                              params_base, perc_uncert,
                                              sep_input_df, N_input_df, 
                                              percentile = 'med', 
                                              MP_flag = MP_flag)
            result6 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {}'.format(sumN50, fut_date)
            print(result6)
            
            result7 = '\n--\nFor the near-maximum (95%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year increase in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result7)
            print('')
            
            sumN95, N_interp_future95, dates_int_future95 = \
                                              future_fraction_uncert(fraction,
                                              user_df, well, fut_date, 
                                              sample_date, params95, 
                                              params_base, perc_uncert,
                                              sep_input_df, N_input_df, 
                                              percentile = 'max',
                                              MP_flag = MP_flag)
            result8 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {} \n'.format(sumN95, fut_date)
            print(result8)
        if x == 2:
            rate, fut_date = var1, var2
            result1 = 'With a future nitrate leaching rate of {} lb/ac for '\
                      'the base realization, \nthe nitrate concentration on '\
                      '{} is expected to be {:.0f} mg/L.'\
                      .format(rate, fut_date, N_return_base)
            print(result1)
            result2 = '\n-----\nUncertainty for scenario 2 is illustrated '\
                      'via 3 Monte Carlo \nrealizations that represent: \n'\
                      'the near-minimum (5%) forecasted nitrate concentration '\
                      'as of {0},\nthe median (50%) forecasted nitrate '\
                      'concentration as of {0}, and \nthe near-maximum '\
                      '(95%) forecasted nitrate concentration on {0}, \nas '\
                      'follows:'.format(rank_realz_date)
            print(result2)
            
            result3 = '\n--\nFor the near-minimum (5%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year reduction in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result3)
            print('')
            sumN5, rate_2016, N_interp_future5, dates_int_future5 = \
                                                  future_constant_uncert(rate,
                                                  user_df, well, fut_date, 
                                                  sample_date, params5, 
                                                  params_base, perc_uncert,
                                                  sep_input_df, N_input_df,
                                                  percentile = 'min', 
                                                  MP_flag = MP_flag)
            result4 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {}'.format(sumN5, fut_date)
            print(result4)
            
            result5 = '\n--\nFor the median (50%) realization, with zero '\
                      'uncertainty for \nfuture leaching:'
            print(result5)
            print('') 
            sumN50, rate_2016, N_interp_future50, dates_int_future50 = \
                                                  future_constant_uncert(rate,
                                                  user_df, well, fut_date, 
                                                  sample_date, params50, 
                                                  params_base, perc_uncert,
                                                  sep_input_df, N_input_df, 
                                                  percentile = 'med', 
                                                  MP_flag = MP_flag)
            result6 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {}'.format(sumN50, fut_date)
            print(result6)
            
            result7 = '\n--\nFor the near-maximum (95%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year increase in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result7)
            print('')
            
            sumN95, rate_2016, N_interp_future95, dates_int_future95 = \
                                                  future_constant_uncert(rate,
                                                  user_df, well, fut_date, 
                                                  sample_date, params95, 
                                                  params_base, perc_uncert,
                                                  sep_input_df, N_input_df, 
                                                  percentile = 'max',
                                                  MP_flag = MP_flag)
            result8 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {} \n'.format(sumN95, fut_date)
            print(result8)
        if x == 3:
            fraction, fut_date = var1, var2
            result1 = 'With a future nitrate leaching rate of {:.0%} of '\
                      'current rates for the base \nrealization, the nitrate '\
                      'concentration on {} is expected to be {:.0f} mg/L.'\
                      .format(fraction, fut_date, N_return_base)
            print(result1)
            result2 = '\n-----\nUncertainty for scenario 3 is illustrated '\
                      'via 3 Monte Carlo \nrealizations that represent: \n'\
                      'the near-minimum (5%) forecasted nitrate concentration '\
                      'as of {0},\nthe median (50%) forecasted nitrate '\
                      'concentration as of {0}, and \nthe near-maximum '\
                      '(95%) forecasted nitrate concentration on {0}, \nas '\
                      'follows:'.format(rank_realz_date)
            print(result2) 
            
            result3 = '\n--\nFor the near-minimum (5%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year reduction in future leaching rates:\n'\
                      .format(perc_uncert*100)

            sumN5, N_interp_future5, dates_int_future5 = \
                                              future_fraction_uncert(fraction,
                                              user_df, well, fut_date, 
                                              sample_date, params5, 
                                              params_base, perc_uncert,
                                              sep_input_df, N_input_df,
                                              percentile = 'min', 
                                              MP_flag = MP_flag)
            result4 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {}'.format(sumN5, fut_date)
            print(result3, '\n', result4)
            
            result5 = '\n--\nFor the median (50%) realization, with zero '\
                      'uncertainty for \nfuture leaching:\n'

            sumN50, N_interp_future50, dates_int_future50 = \
                                              future_fraction_uncert(fraction,
                                              user_df, well, fut_date, 
                                              sample_date, params50, 
                                              params_base, perc_uncert,
                                              sep_input_df, N_input_df, 
                                              percentile = 'med', 
                                              MP_flag = MP_flag)
            result6 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {}'.format(sumN50, fut_date)
            print(result5, '\n', result6)
            
            result7 = '\n--\nFor the near-maximum (95%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year increase in future leaching rates:\n'\
                      .format(perc_uncert*100)
            
            sumN95, N_interp_future95, dates_int_future95 = \
                                              future_fraction_uncert(fraction,
                                              user_df, well, fut_date, 
                                              sample_date, params95, 
                                              params_base, perc_uncert,
                                              sep_input_df, N_input_df, 
                                              percentile = 'max',
                                              MP_flag = MP_flag)
            result8 = 'The future concentration is expected to be '\
                      '{:.0f} mg/L on {} \n'.format(sumN95, fut_date)
            print(result7, '\n', result8)
            
        if x == 4:
            # Printing of base case results is done in the run_futures 
            # function to ensure analysis below is based upon optimized
            # future load rather than "current" rate.
            result1 = '-----\nUncertainty for scenario 4 is illustrated '\
                      'via 3 Monte Carlo \nrealizations that represent: \n'\
                      'the near-minimum (5%) forecasted nitrate concentration '\
                      'as of {0},\nthe median (50%) forecasted nitrate '\
                      'concentration as of {0}, and \nthe near-maximum '\
                      '(95%) forecasted nitrate concentration on {0}, \nas '\
                      'follows:\n'.format(rank_realz_date)
            print(result1) 
            
            result2 = '--\nFor the near-minimum (5%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year reduction in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result2)
            print('')
            frac_guess = 1
            fraction5, result3 = opt_frac_uncert(frac_guess, user_df, N_goal,
                                                 well, fut_date, sample_date, 
                                                 params5, params_base, 
                                                 perc_uncert, sep_input_df, 
                                                 N_input_df, shift,
                                                 percentile = 'min', 
                                                 MP_flag = MP_flag, 
                                                 print_out = True)
            if fraction5 > 1.0:
                fraction5 = 1.0   
            sumN5, N_interp_future5, dates_int_future5 = \
                                             future_fraction_uncert(fraction5,
                                             user_df, well, fut_date, 
                                             sample_date, params5, 
                                             params_base, perc_uncert,
                                             sep_input_df, N_input_df,
                                             percentile = 'min', 
                                             MP_flag = MP_flag)
            
            result4 = '--\nFor the median (50%) realization, with zero '\
                      'uncertainty for \nfuture leaching:'
            print(result4)
            print('')
            fraction50, result5 = opt_frac_uncert(frac_guess, user_df, N_goal,
                                                  well, fut_date, sample_date,
                                                  params50, params_base, 
                                                  perc_uncert, sep_input_df,
                                                  N_input_df, shift, 
                                                  percentile = 'med', 
                                                  MP_flag = MP_flag, 
                                                  print_out = True)
            if fraction50 > 1.0:
                fraction50 = 1.0
            sumN50, N_interp_future50, dates_int_future50 = \
                                            future_fraction_uncert(fraction50,
                                            user_df, well, fut_date, 
                                            sample_date, params50, 
                                            params_base, perc_uncert,
                                            sep_input_df, N_input_df, 
                                            percentile = 'med', 
                                            MP_flag = MP_flag)
            
            result6 = '--\nFor the near-maximum (95%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year increase in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result6)
            print('')
            fraction95, result7 = opt_frac_uncert(frac_guess, user_df, N_goal,
                                                  well, fut_date, sample_date, 
                                                  params95, params_base, 
                                                  perc_uncert, sep_input_df, 
                                                  N_input_df, shift, 
                                                  percentile = 'max',
                                                  MP_flag = MP_flag, 
                                                  print_out = True)
            if fraction95 > 1.0:
                fraction95 = 1.0
            sumN95, N_interp_future95, dates_int_future95 = \
                                            future_fraction_uncert(fraction95,
                                            user_df, well, fut_date, 
                                            sample_date, params95, 
                                            params_base, perc_uncert,
                                            sep_input_df, N_input_df, 
                                            percentile = 'max',
                                            MP_flag = MP_flag)
            result8 = ''
                
        if x == 5:
            # Printing of base case results is done in the run_futures 
            # function to ensure analysis below is based upon optimized 
            # future load rather than "current" rate.
            result1 = '-----\nUncertainty for scenario 5 is illustrated '\
                      'via 3 Monte Carlo \nrealizations that represent: \n'\
                      'the near-minimum (5%) forecasted nitrate concentration '\
                      'as of {0},\nthe median (50%) forecasted nitrate '\
                      'concentration as of {0}, and \nthe near-maximum '\
                      '(95%) forecasted nitrate concentration on {0}, \nas '\
                      'follows:\n'.format(rank_realz_date)
            print(result1) 
            
            result2 = '--\nFor the near-minimum (5%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year reduction in future leaching rates:'\
                      .format(perc_uncert*100)    
            print(result2)
            print('')        
            slope_guess = 0
            fraction5, result3 = opt_slope_uncert(slope_guess, user_df,
                                                  N_goal, well, fut_date,
                                                  sample_date, params5, 
                                                  params_base, perc_uncert,
                                                  sep_input_df, N_input_df, 
                                                  shift, percentile = 'min',
                                                  MP_flag = MP_flag, 
                                                  print_out = True)
            if fraction5 > 0.0:
                fraction5 = 0.0      
            sumN5, zero_date5, final_rate5, N_interp_future5, \
            dates_int_future5 = future_slope_uncert_calc(fraction5, user_df,
                                        well, fut_date, sample_date, params5, 
                                        params_base, perc_uncert, 
                                        sep_input_df, N_input_df, 
                                        percentile = 'min',MP_flag = MP_flag) 
                                                                                 
            
            result4 = '--\nFor the median (50%) realization, with zero '\
                      'uncertainty for \nfuture leaching:'
            print(result4)
            print('')
            fraction50, result5 = opt_slope_uncert(slope_guess, user_df,
                                                   N_goal, well, fut_date,
                                                   sample_date, params50, 
                                                   params_base, perc_uncert,
                                                   sep_input_df, N_input_df, 
                                                   shift, percentile = 'med', 
                                                   MP_flag = MP_flag, 
                                                   print_out = True)
            if fraction50 > 0.0:
                fraction50 = 0.0
            sumN50, zero_date50, final_rate50, N_interp_future50, \
            dates_int_future50 = future_slope_uncert_calc(fraction50, user_df,
                                        well, fut_date, sample_date, params50,
                                        params_base, perc_uncert,
                                        sep_input_df, N_input_df,
                                        percentile = 'med', MP_flag = MP_flag)
            
            result6 = '--\nFor the near-maximum (95%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year increase in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result6)
            print('')
            fraction95, result7 = opt_slope_uncert(slope_guess, user_df,
                                                   N_goal, well, fut_date,
                                                   sample_date, params95, 
                                                   params_base, perc_uncert,
                                                   sep_input_df, N_input_df, 
                                                   shift, percentile = 'max',
                                                   MP_flag = MP_flag, 
                                                   print_out = True)
            if fraction95 > 0.0:
                fraction95 = 0.0
            sumN95, zero_date95, final_rate95, N_interp_future95,  \
            dates_int_future95 = future_slope_uncert_calc(fraction95, user_df, 
                                        well, fut_date, sample_date, params95,
                                        params_base, perc_uncert, 
                                        sep_input_df, N_input_df, 
                                        percentile = 'max', MP_flag = MP_flag) 
            result8 = ''
            
        if x == 6:
            # Printing of base case results is done in the run_futures 
            # function to ensure analysis below is based upon optimized
            # future load rather than "current" rate.
            N_goal, rate = var1, var2
            
            result1 = '\n-----\nUncertainty for scenario 6 is illustrated '\
                      'via 3 Monte Carlo \nrealizations that represent: \n'\
                      'the near-minimum (5%) forecasted nitrate concentration '\
                      'as of {0},\nthe median (50%) forecasted nitrate '\
                      'concentration as of {0}, and \nthe near-maximum '\
                      '(95%) forecasted nitrate concentration on {0}, \nas '\
                      'follows:'.format(rank_realz_date)
            print(result1)
            
            result2 = '\n--\nFor the near-minimum (5%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year reduction in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result2)
            print('')
            fut_year5, result3 = opt_date_uncert(N_goal, rate, user_df, well,
                                                 sample_date, params5,
                                                 params_base, perc_uncert, 
                                                 sep_input_df, N_input_df,
                                                 shift, percentile = 'min', 
                                                 MP_flag = MP_flag, 
                                                 guess_date = 2100,
                                                 print_out = True)
                                        
            if fut_year5 == 'N/A - below':
                fut_year5 = max(dates_int_future_base)
            if fut_year5 == 'N/A - above':
                fut_year5 = 2100
            sumN5, rate_prior5, N_interp_future5, dates_int_future5 = \
                                            future_constant_uncert(rate,
                                            user_df, well, 
                                            '01/01/{}'.format(int(fut_year5)),
                                            sample_date, params5, params_base, 
                                            perc_uncert, sep_input_df, 
                                            N_input_df, percentile = 'min', 
                                            MP_flag = MP_flag)
            
            result4 = '\n--\nFor the median (50%) realization, with zero '\
                      'uncertainty for \nfuture leaching:'
            print(result4)
            print('')
            fut_year50, result5 = opt_date_uncert(N_goal, rate, user_df, well,
                                                  sample_date, params50,
                                                  params_base, perc_uncert, 
                                                  sep_input_df, N_input_df,
                                                  shift, percentile = 'med', 
                                                  MP_flag = MP_flag, 
                                                  guess_date = 2100,
                                                  print_out = True)
            if fut_year50 == 'N/A - below':
                fut_year50 = max(dates_int_future_base)
            if fut_year50 == 'N/A - above':
                fut_year50 = 2100
            sumN50, rate_prior50, N_interp_future50, dates_int_future50 = \
                                           future_constant_uncert(rate,
                                           user_df, well, 
                                           '01/01/{}'.format(int(fut_year50)),
                                           sample_date, params50, params_base, 
                                           perc_uncert, sep_input_df, 
                                           N_input_df, percentile = 'med', 
                                           MP_flag = MP_flag)
            
            result6 = '\n--\nFor the near-maximum (95%) realization, with '\
                      'assumed uncertainty \naccounting for a {:.0f}% per '\
                      'year increase in future leaching rates:'\
                      .format(perc_uncert*100)
            print(result6)
            print('')
            fut_year95, result7 = opt_date_uncert(N_goal, rate, user_df, well,
                                                  sample_date, params95,
                                                  params_base, perc_uncert, 
                                                  sep_input_df, N_input_df,
                                                  shift, percentile = 'max', 
                                                  MP_flag = MP_flag, 
                                                  guess_date = 2100,
                                                  print_out = True)
            if fut_year95 == 'N/A - below':
                fut_year95 = max(dates_int_future_base)
            if fut_year95 == 'N/A - above':
                fut_year95 = 2100
            sumN95, rate_prior95, N_interp_future95, dates_int_future95 = \
                                           future_constant_uncert(rate,
                                           user_df, well, 
                                           '01/01/{}'.format(int(fut_year95)),
                                           sample_date, params95, params_base,
                                           perc_uncert, sep_input_df, 
                                           N_input_df, percentile = 'max', 
                                           MP_flag = MP_flag)
                                                                          
            result8 = ''
        
        if shift2mean:
            if shift >= 0.0:
                updown = 'up'
            else:
                updown = 'down'
            if x in [1, 2, 3]:
                print_shift = '\n \n****************************************'\
                '************************\nYou have selected to shift the '\
                'simulated results to match the mean\nof measured nitrate '\
                'values.  As a result, the nitrate concentration\ngraphs '\
                '(at the bottom) have been shifted {} by {:.2f} mg/L. \n'\
                '***********************************************************'\
                '*****\n\n'.format(updown, shift)
                print(print_shift)
            else:
                print_shift = '\n \n****************************************'\
                '************************\nYou have selected to shift the '\
                'simulated results to match the mean\nof measured nitrate '\
                'values.  As a result, the nitrate concentration\ngraphs ' \
                '(at the bottom) have been shifted {} by {:.2f} mg/L. \n\n'\
                'The computed reductions in leached nitrate (lb/ac/yr) are '\
                'influened by \nthis shift value, so you are encouraged to '\
                're-run this code block using\nshift2mean=False to assess '\
                'the differences, and to potentially use both\n'\
                'sets of results when considering a decision.\n'\
                '***********************************************************'\
                '*****\n\n'.format(updown, shift)
                print(print_shift)
        else:
            print_shift = ''
        
        rank_realz_date = datetime.strptime(rank_realz_date, '%m/%d/%Y')
        txtrealz =  f'Of the {len(MC_params)} total realizations, the individual realizations '\
                f'used for displaying uncertainty \nwere ranked and '\
                f'identified as the 5th, 50th, and 95th percentiles based on '\
                f'\nconcentrations simulated for: {rank_realz_date:%m-%d-%Y}.\n'
        #txt6 = ''
        
        if user_params_mults == 'default':
            partxt1 = 'All model parameters were set to their default '\
                      'calibrated values (no "User Interaction").'
            partxt2 = ''
        else:
            partxt1 = 'Model parameters were multiplied by the user supplied'\
                      ' user_params_mults dictionary:\n'
            partxt2 = [f'{key} : {value}' 
                       for key, value in user_params_mults.items()]
        
        txt_combined = txt1 + '\n' + txt2 + '\n' + txtrealz + '\n' +\
                       partxt1 + '\n'.join(partxt2) + '\n' + \
                       print_shift + '\n' + txtx + '\n' + \
                       txtvar1 + txtvar2 + txtuncert + '\n\n' +\
                       txtres1 + '\n' + txtres2 + '\n' + txtres3 + '\n' + \
                       extra_var2_base + '\n' + result1 + '\n' + result2 + \
                       '\n' + result3 + '\n' + result4 + '\n' + result5 + \
                       '\n' + result6 + '\n' + result7 + '\n' + result8
                       
        firstPage = plt.figure(figsize = (8.5, 11))
        firstPage.clf()
        datenow = datetime.now().strftime("%m/%d/%Y")
        timenow = datetime.now().strftime("%I:%M%p")
        firstPage.text(0.15,0.92,'This file is a log of certain GW-NDST '
             'inputs, results (graphs), \nand details about the python '
             'environment used to run the \n"cs.future_scenarios" on '
             '{} at {}.'.format(datenow, timenow),
             transform=firstPage.transFigure, size=14, linespacing = 1.25, 
             ha="left")
        firstPage.text(0.15,0.88,"\nUser's well input path and file name:\n", 
                     transform=firstPage.transFigure, size=10, linespacing = 1, 
                     ha="left")
        firstPage.text(0.55,0.88,'{}\n'.format(input_file), 
                     transform=firstPage.transFigure, size=10, linespacing = 1, 
                     ha="left")
        
        firstPage.text(0.15,0.05,txt_combined, transform=firstPage.transFigure,
                       size=8, linespacing = 1.15, ha="left")
        pdf.savefig()
        plt.close()        
        
        #########################################################
        ##########               PLOTTING              ##########
        #########################################################
                
        this_year = datetime.today().year  
        year_frac = smp_dt - year
        if high_res == False:
            if year%10 != 0:
                year = (year//10)*10
            if this_year%10 != 0:
                this_year = (this_year//10)*10
        d2 = [i for i in dates_int_future_base if i >= this_year - year_frac]   
        
        print()  # extra space between text and plot.
        
        # Figure(1)
        if density_plot and x in [1, 2, 3, 4, 5]:
                data = run_ensemble(MC_params_plus, x, var1, var2, user_df, 
                                    well, sample_date, params_orig,
                                    params_base, perc_uncert, sep_input_df, 
                                    N_input_df, high_res, shift, user_params_mults,
                                    MP_flag = False)
                
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (8.5, 6),
                                        gridspec_kw={'width_ratios': [7, 1], 
                                        'hspace' : 0, 'wspace' : 0},
                                        tight_layout = True)
        else:
            data = None
            fig, ax1 = plt.subplots(1, 1, figsize = (8.5, 6))

        # Run functions to generate historical load for plotting
        thisnewyeardate = '01/01/{}'.format(int(datetime.today().year))
        N_join_5, N_interp_5, dates_interp_5, N_total_5 = \
                              N_interpolate(user_df, well, thisnewyeardate, 
                                            params5, sep_input_df, 
                                            N_input_df, MP_flag)
        N_join_50, N_interp_50, dates_interp_50, N_total_50 = \
                              N_interpolate(user_df, well, thisnewyeardate, 
                                            params50, sep_input_df, 
                                            N_input_df, MP_flag)
        N_join_95, N_interp_95, dates_interp_95, N_total_95 = \
                              N_interpolate(user_df, well, thisnewyeardate, 
                                            params95, sep_input_df, 
                                            N_input_df, MP_flag)
        if x == 6:
            max_plt_date = f'01/01/{int(np.ceil(np.max(dates_int_future95)))}'
            sumN_x5, rate_prior_x5, N_interp_future5, \
                            dates_int_future5 = future_constant_uncert(rate,
                                                user_df, well, max_plt_date, 
                                                sample_date, params5,
                                                params_base, perc_uncert, 
                                                sep_input_df, N_input_df,
                                                percentile = 'min', 
                                                MP_flag = MP_flag)
            sumN_x50, rate_prior_x50, N_interp_future50, \
                        dates_int_future50 = future_constant_uncert(rate,
                                            user_df, well, max_plt_date, 
                                            sample_date, params50, 
                                            params_base, perc_uncert,
                                            sep_input_df, N_input_df,
                                            percentile = 'med', 
                                            MP_flag = MP_flag)
            sumN_xbase, rate_prior_xbase, N_interp_future_base, \
                        dates_int_future_base = future_constant_uncert(rate,
                                            user_df, well, max_plt_date, 
                                            sample_date, params_base, 
                                            params_base, perc_uncert,
                                            sep_input_df, N_input_df,
                                            percentile = 'med', 
                                            MP_flag = MP_flag)
            d2 = [i for i in dates_int_future_base if i >= this_year - year_frac]                                
                                            
        d5 = [i for i in dates_int_future5 if i >= this_year - year_frac]  
        d50 = [i for i in dates_int_future50 if i >= this_year - year_frac]
        d95 = [i for i in dates_int_future95 if i >= this_year - year_frac]
        
        # Historical realizations with solid lines; future with dashed
        ax1.plot(dates_interp_5, N_interp_5.N_sum, color = 'cornflowerblue',
                 alpha = 0.5, label = 'Near min (5%) realization')  # label=0
        ax1.plot(d5, N_interp_future5.N_sum.values[0:len(d5)], 
                 color = 'cornflowerblue', alpha = 0.5,
                 linestyle = '--', label = '5% (near minimum) realization')  
                 # label = 1
        ax1.plot(dates_interp_50, N_interp_50.N_sum, color = 'coral',
                 label = 'Median (50%) realization') # label = 2
        ax1.plot(d50, N_interp_future50.N_sum.values[0:len(d50)], 
                 color = 'coral', linestyle = '--', 
                 label = '50% (median) realization')  # label = 3
        ax1.plot(dates_interp_95, N_interp_95.N_sum, color = 'mediumseagreen',
                 alpha = 0.5, label = 'Near max (95%) realization')  # label=4
        ax1.plot(d95, N_interp_future95.N_sum.values[0:len(d95)],  alpha = 0.5,
                 color = 'mediumseagreen', linestyle = '--', 
                 label = '95% (near maximum) realization')  # label = 5
        
        ax1.plot(N_total_base.loc[:this_year].N_sum, color = 'black', 
                 label = 'Base realization')  # label = 6
        ax1.plot(d2, N_interp_future_base.N_sum.values[0:len(d2)], 
                 color = 'black', linestyle = '--', 
                 label = 'Base realization in the future')  # label = 7
        
        fig.suptitle('Nitrate Leaching Over Time at Well {}'.format(well_id))         
        handles, labels = ax1.get_legend_handles_labels()
        order = [6,4,2,0]
        handles_list = [handles[idx] for idx in order]
        labels_list = [labels[idx] for idx in order]
        # A ymax value higher than the max of the 4 lines is needed because 
        # the density plot is likely to exceed the default ymax value.
        ymaxbase = np.max([np.max(N_interp_future_base.N_sum), 
                            np.max(N_total_base.N_sum)])
        ymax95 = np.max([np.max(N_interp_future95.N_sum), 
                        np.max(N_interp_95.N_sum)])
        ymax50 = np.max([np.max(N_interp_future50.N_sum), 
                        np.max(N_interp_50.N_sum)])
        ymax5 = np.max([np.max(N_interp_future5.N_sum), 
                        np.max(N_interp_5.N_sum)])
        ymax = np.max([ymaxbase, ymax95, ymax50, ymax5])*1.1  # no density plot
        xmax = np.max([np.max(decades_base), np.max(d95)])
        try:
            plt_xmax = int(fut_date.split('/')[-1])
        except:
            plt_xmax = xmax

        if x in [1, 2, 3, 4, 5]:
            if density_plot:
                ymax = np.max([ymaxbase, ymax95, ymax50, ymax5]) *1.25
                ax1.set_xlim(1960, plt_xmax)
                bins = ax2.hist(data.other_data, bins = 25, 
                            orientation = 'horizontal', color = 'grey', 
                            label = 'All Realizations')
                ax2.set_xlim(0,np.max(bins[0])*1.25)
                ax2.set_ylim(0, ymax)
                ax2.set_xticklabels([])
                ax2.set_xticks([])
                ax2.set_yticklabels([])
                ax2.set_yticks([])
                handles2, labels2 = ax2.get_legend_handles_labels()
                ax1.legend(np.append(handles_list, handles2),
                        np.append(labels_list, labels2), loc='upper left', 
                        fontsize='small', framealpha=0.4, title=shift_title)

            else:
                ax1.set_xlim(1960, plt_xmax)
                ax1.legend(handles_list, labels_list, loc='upper left', 
                    fontsize='small', framealpha=0.4, title=shift_title)

        else:
            ax1.set_xlim(1960, plt_xmax)
            ax1.legend(handles_list, labels_list, loc='best', 
                    fontsize='small', framealpha=0.4, title=shift_title)
                
        ax1.set_xlabel('Year')
        ax1.set_ylabel('Nitrate leached (lb/ac)')
        ax1.set_ylim(0, ymax)
        if plt_xmax < 2060:
            tick_diff = 10
        else:
            tick_diff = 20
        ax1.set_xticks(np.arange(1960, plt_xmax + 1, tick_diff), 
                        np.arange(1960, plt_xmax + 1, tick_diff))
        ax1.set_xticklabels(np.arange(1960, plt_xmax + 1, tick_diff, 
                            dtype = 'int'))
        pdf.savefig(1)
        
        # Figure 2
        plt.figure(2, figsize = (8.5, 6))
        # Plot uncertainty lines first so base case is on top.
        try:
            idx = np.where(tt_base > mean_tt_base*4)[0][0]
        except:
            idx = np.argmax(tt_base)

        plt.plot(tt5[:idx], g_t5[:idx], color = 'cornflowerblue', alpha = 0.5,
                 label = 'Near min (5%) realization; \nmean age = {:.0f} '
                         'years'.format(mean_tt5))
        plt.plot(tt50[:idx], g_t50[:idx], color = 'coral', 
                 label = 'Median (50%) realization; \nmean age = {:.0f} '
                         'years'.format(mean_tt50))
        plt.plot(tt95[:idx], g_t95[:idx], color = 'mediumseagreen', 
                 alpha = 0.5, 
                 label = 'Near max (95%) realization; \nmean age = {:.0f} '
                         'years'.format(mean_tt95))
        
        plt.plot(tt_base[:idx], g_t_base[:idx], color = 'black', 
                 label = 'Base realization; \nmean age = {:.0f} '
                         'years'.format(mean_tt_base))
              
        plt.xlabel('Age in Years')
        plt.ylabel('Probability')
        plt.yticks(fontsize = 7)
        plt.title('Age Distribution at Well {}'.format(well_id))                  

        handles, labels = plt.gca().get_legend_handles_labels()
        order = [3,2,1,0]
        plt.legend([handles[idx] for idx in order],[labels[idx] 
                   for idx in order], framealpha=0.4, fontsize='small', 
                   loc='best')
        pdf.savefig(2)      
            
        # Generate info needed for plotting figure 3.
        # dec_fut is overwritten for scen 4-6, but needed for scen 1-3.
        #dec_fut = [i for i in decades_base if i >= this_year]  
        #dec_hist = [i for i in decades_base if (1960 <= i <= this_year)]
        
        # For Scenario 6, each realization has a different number of years        
        if x == 6: 
            max_date = int(max([max(dates_int_future5),
                                max(dates_int_future50), 
                                max(dates_int_future95)]))
            # Used for appending base case below.         
            base_max_date = int(max(decades_base))   
            # add 10 years to max_date and base_max_date
            # consider renaming to something like base_end_date or something
            # that better explains what this variable is
        else:  
            max_date = int(max(decades_base))
        if high_res == False:
            decades = np.linspace(1960, np.floor(max_date/10)*10, 
                      int((np.floor(max_date/10)*10-1960)/10+1), dtype = int)
        else:
            decades = np.linspace(1960, (max_date), (max_date - 1959), 
                      dtype = int)
        
        # Initiate empty lists
        dates, N_dec5, N_dec50, N_dec95 = \
                ([None]*len(decades) for i in range(4))  
        dec_fut = [i for i in decades if i >= this_year]
        dec_hist = [i for i in decades if (1960 <= i <= this_year)]
        
        for i in range(0, len(dates)):
            dates[i] = '01/01/{}'.format(decades[i])
        
            # Use N_convolve function to populate historical concentrations
            if datetime.strptime(dates[i], "%m/%d/%Y") < datetime.today():
                sumN_i2 = N_convolve(user_df, well, str(dates[i]), params5,
                                     sep_input_df, N_input_df, MP_flag)
                sumN_i3 = N_convolve(user_df, well, str(dates[i]), params50, 
                                     sep_input_df, N_input_df, MP_flag)
                sumN_i4 = N_convolve(user_df, well, str(dates[i]), params95, 
                                     sep_input_df, N_input_df, MP_flag)
                N_dec5[i] = sumN_i2
                N_dec50[i] = sumN_i3
                N_dec95[i] = sumN_i4
            # Use future functions to populate forecasted concentrations
            else:  
                if x in [1, 3]:
                    sumN_i5, N_interp_future_x5, dates_int_future_x5 = \
                                              future_fraction_uncert(fraction,
                                              user_df, well, str(dates[i]),
                                              sample_date, params5, 
                                              params_base, perc_uncert,
                                              sep_input_df, N_input_df,
                                              percentile = 'min', 
                                              MP_flag = MP_flag)
                    sumN_i50, N_interp_future_x50, dates_int_future_x50 = \
                                              future_fraction_uncert(fraction,
                                              user_df, well, str(dates[i]),
                                              sample_date, params50, 
                                              params_base, perc_uncert, 
                                              sep_input_df, N_input_df,
                                              percentile = 'med', 
                                              MP_flag = MP_flag)
                    sumN_i95, N_interp_future_x95, dates_int_future_x95 = \
                                              future_fraction_uncert(fraction,
                                              user_df, well, str(dates[i]),
                                              sample_date, params95, 
                                              params_base, perc_uncert, 
                                              sep_input_df, N_input_df,
                                              percentile = 'max', 
                                              MP_flag = MP_flag)
                                                                          
                if x == 2:
                    sumN_i5, rate_2016, N_interp_future_x5, \
                    dates_int_future_x5 = future_constant_uncert(rate, 
                                                user_df, well, str(dates[i]),                        
                                                sample_date, params5, 
                                                params_base, perc_uncert, 
                                                sep_input_df, N_input_df,
                                                percentile = 'min', 
                                                MP_flag = MP_flag)
                    sumN_i50, rate_2016, N_interp_future_x50, \
                    dates_int_future_x50 = future_constant_uncert(rate,
                                                 user_df, well, str(dates[i]),
                                                 sample_date, params50, 
                                                 params_base, perc_uncert, 
                                                 sep_input_df, N_input_df,
                                                 percentile = 'med', 
                                                 MP_flag = MP_flag)
                    sumN_i95, rate_2016, N_interp_future_x95, \
                    dates_int_future_x95 = future_constant_uncert(rate,
                                                 user_df, well, str(dates[i]),
                                                 sample_date, params95, 
                                                 params_base, perc_uncert, 
                                                 sep_input_df, N_input_df,                         
                                                 percentile = 'max', 
                                                 MP_flag = MP_flag)
                
                if x == 4:
                    sumN_i5, N_interp_future_x5, dates_int_future_x5 = \
                                             future_fraction_uncert(fraction5,
                                             user_df, well, str(dates[i]),
                                             sample_date, params5, 
                                             params_base, perc_uncert, 
                                             sep_input_df, N_input_df,
                                             percentile = 'min', 
                                             MP_flag = MP_flag)
                    sumN_i50, N_interp_future_x50, dates_int_future_x50 = \
                                            future_fraction_uncert(fraction50,
                                            user_df, well, str(dates[i]),
                                            sample_date, params50, 
                                            params_base, perc_uncert, 
                                            sep_input_df, N_input_df,
                                            percentile = 'med', 
                                            MP_flag = MP_flag)
                    sumN_i95, N_interp_future_x95, dates_int_future_x95 = \
                                            future_fraction_uncert(fraction95,
                                            user_df, well, str(dates[i]),
                                            sample_date, params95, 
                                            params_base, perc_uncert, 
                                            sep_input_df, N_input_df,
                                            percentile = 'max', 
                                            MP_flag = MP_flag)
                
                if x == 5:
                    sumN_i5, zero_date_x5, final_rate_x5, N_interp_future_x5, \
                    dates_int_future_x5 = future_slope_uncert_calc(fraction5,
                                          user_df, well, str(dates[i]), 
                                          sample_date, params5,
                                          params_base, perc_uncert, 
                                          sep_input_df, N_input_df,
                                          percentile = 'min', 
                                          MP_flag = MP_flag)
                    sumN_i50, zero_date_x50, final_rate_x50,    \
                    N_interp_future_x50, dates_int_future_x50 = \
                                          future_slope_uncert_calc(fraction50,
                                          user_df, well, str(dates[i]), 
                                          sample_date, params50,
                                          params_base, perc_uncert, 
                                          sep_input_df, N_input_df,
                                          percentile = 'med', 
                                          MP_flag = MP_flag)
                    sumN_i95, zero_date_x95, final_rate_x95,    \
                    N_interp_future_x95, dates_int_future_x95 = \
                                          future_slope_uncert_calc(fraction95,
                                          user_df, well, str(dates[i]), 
                                          sample_date, params95,
                                          params_base, perc_uncert, 
                                          sep_input_df, N_input_df,
                                          percentile = 'max', 
                                          MP_flag = MP_flag)
                
                if x == 6:
                    sumN_i5, rate_prior_x5, N_interp_future_x5, \
                    dates_int_future_x5 = future_constant_uncert(rate,
                                          user_df, well, str(dates[i]), 
                                          sample_date, params5,
                                          params_base, perc_uncert, 
                                          sep_input_df, N_input_df,
                                          percentile = 'min', 
                                          MP_flag = MP_flag)
                    sumN_i50, rate_prior_x50, N_interp_future_x50, \
                    dates_int_future_x50 = future_constant_uncert(rate,
                                           user_df, well, str(dates[i]), 
                                           sample_date, params50, 
                                           params_base, perc_uncert,
                                           sep_input_df, N_input_df,
                                           percentile = 'med', 
                                           MP_flag = MP_flag)
                    sumN_i95, rate_prior_x95, N_interp_future_x95, \
                    dates_int_future_x95 = future_constant_uncert(rate,
                                           user_df, well, str(dates[i]), 
                                           sample_date, params95,
                                           params_base, perc_uncert,
                                           sep_input_df, N_input_df, 
                                           percentile = 'max', 
                                           MP_flag = MP_flag)
                    # For scen 6, add on to the base run to match max 
                    # duration from the scenarios.
                    if datetime.strptime(dates[i], "%m/%d/%Y") > \
                        datetime.strptime('01/01/{}'.format(base_max_date), 
                                         "%m/%d/%Y"):
                        sumN_baseF, rate_prior_baseF, N_interp_future_baseF, \
                        dates_int_future_baseF = future_constant_uncert(
                                rate, user_df, well, str(dates[i]), sample_date, 
                                params_base, params_base, perc_uncert, 
                                sep_input_df, N_input_df, percentile = 'med', 
                                MP_flag = MP_flag)
                        N_dec_base = np.append(N_dec_base, sumN_baseF, 
                                                axis = None)
                        
                N_dec5[i] = sumN_i5
                N_dec50[i]= sumN_i50
                N_dec95[i] = sumN_i95
                
        # plt.figure(3)    
        # Plot uncertainties first so base case is on top.
        if density_plot:
            if x in [1, 2, 3, 4, 5]:
                    
                fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (8.5, 6),
                        gridspec_kw=
                        {'width_ratios': [7, 1], 'hspace' : 0, 'wspace' : 0},
                         tight_layout = True)
                
            else:
                data = run_ensemble(MC_params_plus, x, var1, var2, user_df, 
                                    well, sample_date, params_orig,
                                    params_base, perc_uncert, sep_input_df, 
                                    N_input_df, high_res, shift, user_params_mults,
                                    MP_flag = False)
                fig, ax1 = plt.subplots(1, 1, figsize = (8.5, 6))
            
        else:
            data = None
            fig, ax1 = plt.subplots(1, 1, figsize = (8.5, 6))
        
        if x in [4, 5, 6]:
            if x == 6:
                try:
                    plt_xmax = int(np.nanmax([plt_xmax, 
                                    int(np.nanmax(data.other_data.values))]))
                except:
                    plt_xmax = int(np.nanmax(plt_xmax))
            ax1.hlines(N_goal+shift, 1960, plt_xmax, 
                       label = 'Goal $NO_3$ conc. ({:.1f} mg/L)'
                       .format(N_goal+shift), color = 'gray', 
                       alpha = 0.7) # label 0
        
        ax1.plot(dec_hist, N_dec5[:len(dec_hist)]+shift, 
                 color = 'cornflowerblue', alpha = 0.5,
                 label = 'Near min (5%) realization')  # label = 0 or 1
        ax1.plot(dec_fut, N_dec5[-len(dec_fut):]+shift, 
                 color = 'cornflowerblue', alpha = 0.5,
                 linestyle='--', label = 'Near min (5%) realization')  
                 # label = 1 or 2 (pending if a scenario w/ a goal)
        
        ax1.plot(dec_hist, N_dec50[:len(dec_hist)]+shift, color = 'coral', 
                 label = 'Median (50%) realization')  # label = 2 or 3
        ax1.plot(dec_fut, N_dec50[-len(dec_fut):]+shift, color = 'coral', 
                 linestyle='--', label = 'Median (50%) realization')  
                 # label = 3 or 4

        ax1.plot(dec_hist, N_dec95[:len(dec_hist)]+shift, 
                 color = 'mediumseagreen', alpha = 0.5,
                 label = 'Near max (95%) realization')  # label = 4 or 5
        ax1.plot(dec_fut, N_dec95[-len(dec_fut):]+shift, 
                 color = 'mediumseagreen', linestyle='--', alpha = 0.5,
                 label = 'Near max (95%) realization')  # label = 5 or 6
            
        ax1.plot(dec_hist, N_dec_base[:len(dec_hist)]+shift, color = 'black',
                 label = 'Base realization')
        ax1.plot(dec_fut, N_dec_base[-len(dec_fut):]+shift, color = 'black', 
                 linestyle = '--', label = 'Base realization')
        
                 # label = 6 & 7 for scen 1-3; 7 & 8 for scen 4-6

        if usermode == True:
            #if len(multi_sample_dates) > 0:
            if not user_df.NO3_obs.isnull().values.all():
                ax1.scatter(multi_sample_dates, user_df.NO3_obs, 
                            label = 'Measured $NO_3$ conc (mg/L)', 
                            color = 'red', marker = '.', zorder=2)  # label=9
                
        fig.suptitle('Nitrate Concentration Over Time at Well {}'.format(well_id))
        ax1.set_xlabel('Year')
        ax1.set_ylabel('Nitrate (mg/L)')
        
        handles, labels = ax1.get_legend_handles_labels()
        # Only the solid lines above. Loop below grabs the dashed lines
        if x in [4, 5, 6]:
            order = [7,1,3,5]
        else:
            order = [6,0,2,4]
        
        # A ymax value higher than the max of the 4 lines is needed because 
        # the density plot is likely to exceed the default ymax value.
        ymax1 = np.max([np.max(N_dec_base), np.max(N_dec95), np.max(N_dec50), 
                        np.max(N_dec5)])*1.25
        try:
            ymax = np.max([ymax1, np.nanmax(user_df.NO3_obs.values)*1.1])
        except:
            ymax = ymax1
        
        if density_plot:
            if x in [1, 2, 3, 4, 5]:
                ax1.set_xlim(1960, plt_xmax)
                ax1.set_ylim(0, ymax)
                bins = ax2.hist(data.sumN, bins = 25, 
                                orientation = 'horizontal', color = 'grey')
                ax2.set_xlim(0,np.max(bins[0])*1.25)
                ax2.set_ylim(0, ymax)
                ax2.set_xticklabels([])
                ax2.set_xticks([])
                ax2.set_yticklabels([])
                ax2.set_yticks([])
                labels2 = f'All realizations on {fut_date}'
                handles2 = Line2D([0], [0], marker='s', markersize=10, 
                                        markeredgecolor='grey', 
                                        markerfacecolor='grey', linestyle='')
            else:
                ax1.plot(data.other_data, [N_goal + shift]*len(data), '|',
                    markersize = 10, color='grey', zorder = 0)
                labels2 = 'All Realizations'
                handles2 = Line2D([], [], marker = '|', markersize = 10,
                                 linestyle = 'None', markeredgewidth = 1, 
                                 color='grey')
        else:
            ax1.set_xlim(1960, plt_xmax)
            handles2 = None
            labels2 = None
                
        l1 = ax1.legend([(handles[idx], handles[idx+1]) for idx in order], 
             [labels[idx] for idx in order],
            handler_map={tuple: HandlerTuple(ndivide=None)},
            handlelength=3, loc='upper left', framealpha=0.4, fontsize='small', 
            title=shift_title)
        ax1.add_artist(l1)
        if plt_xmax < 2060:
            tick_diff = 10
        else:
            tick_diff = 20
        ax1.set_xticks(np.arange(1960, plt_xmax + 1, tick_diff), 
                        np.arange(1960, plt_xmax + 1, tick_diff))
        ax1.set_xticklabels(np.arange(1960, plt_xmax + 1, tick_diff, 
                            dtype = 'int'))

        if usermode == True:
            if x in [4, 5, 6]:
                #if len(multi_sample_dates) > 0:
                if not user_df.NO3_obs.isnull().values.all():
                    l2 = ax1.legend(handles = [handles[0], handles[9], handles2], 
                                labels = [labels[0],labels[9], labels2], 
                                framealpha=0.4, fontsize='small', 
                                loc = 'lower right')  
                    # Goal & samples
                else:
                    l2 = ax1.legend(handles = [handles[0], handles2], labels = 
                                    [labels[0], labels2], framealpha=0.4, 
                                    fontsize='small', loc = 'lower right')  
                                    # No samples
            else:
                #if len(multi_sample_dates) > 0:
                if not user_df.NO3_obs.isnull().values.all():
                    l2 = ax1.legend(handles = [handles[8], handles2], labels = 
                                    [labels[8], labels2], framealpha=0.4, 
                                    fontsize='small', loc = 'lower right')  
                                    # Samples (no goal)
                else:
                    l2 = ax1.legend(handles = handles2, labels = labels2, 
                                    framealpha=0.4, fontsize='small', 
                                    loc = 'lower right') # No samples or goal
           
            ax1.add_artist(l2)
      
        pdf.savefig(3)
        
        LogPage = plt.figure(figsize = (8.5,11))
        LogPage.clf()
        
        installed_packages = pkg_resources.working_set
        installed_packages_list = sorted(["%s==%s" % (i.key, i.version)
                                            for i in installed_packages])
 
        LogPage.text(0.15,0.92,'Python packages and versions installed in '
                     'the running environment:\n', 
                     transform=LogPage.transFigure,linespacing = 1 ,size=8, 
                     ha="left")
        LogPage.text(0.15,0.025,
                     '\n'.join(installed_packages_list
                               [:int(len(installed_packages_list)/2)]), 
                               transform=LogPage.transFigure, size=8, 
                               linespacing = 1, ha="left")
        LogPage.text(0.5,0.025,
                     '\n'.join(installed_packages_list
                               [int(len(installed_packages_list)/2):]), 
                               transform=LogPage.transFigure, size=8, 
                               linespacing = 1, ha="left")
        pdf.savefig()
        print('These results have been saved to {}'.format(logfilename))
        plt.close()
        
# To aid debugging in an Integrated Development Environment (IDE). 
if __name__ == "__main__":

    input_file = os.path.join(data_in_dir, 'example1.xlsx')
    MP_flag = False
    
    user_params_mults = 'default'
    user_well = ws.WellInfo(input_file).build_user_df(MP_flag)
    user_df = user_well.user_df
    sep_input_df = user_well.sep_input_df
    N_input_df = user_well.N_input_df

    historical_simulation(input_file, user_df, sep_input_df, N_input_df, 
               user_params_mults)

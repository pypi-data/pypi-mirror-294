Metadata-Version: 2.1
Name: pypmc
Version: 1.2.4
Summary: A toolkit for adaptive importance sampling featuring implementations of variational Bayes, population Monte Carlo, and Markov chains.
Home-page: https://github.com/pypmc/pypmc
Author: Frederik Beaujean, Stephan Jahn
Author-email: beaujean@mytum.de, stephan.jahn@mytum.de
License: GPLv2
Platform: Unix
Classifier: Development Status :: 5 - Production/Stable
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: GNU General Public License v2 or later (GPLv2+)
Classifier: Operating System :: Unix
Classifier: Programming Language :: Cython
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Mathematics
Requires-Python: >=3.9
License-File: LICENSE
Requires-Dist: numpy>=1.6
Requires-Dist: scipy
Requires-Dist: setuptools>=40.8.0
Provides-Extra: testing
Requires-Dist: nose; extra == "testing"
Provides-Extra: plotting
Requires-Dist: matplotlib; extra == "plotting"
Provides-Extra: parallelization
Requires-Dist: mpi4py; extra == "parallelization"

``pypmc`` is a python package focusing on adaptive importance
sampling.  It can be used for integration and sampling from a
user-defined target density. A typical application is Bayesian
inference, where one wants to sample from the posterior to marginalize
over parameters and to compute the evidence. The key idea is to create
a good proposal density by adapting a mixture of Gaussian or student's
t components to the target density. The package is able to efficiently
integrate multimodal functions in up to about 30-40 dimensions at the
level of 1% accuracy or less. For many problems, this is achieved
without requiring any manual input from the user about details of the
function. Importance sampling supports parallelization on multiple
machines via ``mpi4py``.

Useful tools that can be used stand-alone include:

* importance sampling (sampling & integration)
* adaptive Markov chain Monte Carlo (sampling)
* variational Bayes (clustering)
* population Monte Carlo (clustering)

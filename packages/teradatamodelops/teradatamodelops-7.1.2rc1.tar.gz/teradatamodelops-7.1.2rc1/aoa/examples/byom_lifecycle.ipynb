{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BYOM Recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aoa import AoaClient\n",
    "\n",
    "client = AoaClient()\n",
    "\n",
    "list(client.projects())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set values for model file and project id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./pima.pmml\"\n",
    "language = \"PMML\"\n",
    "client.project_id = \"23e1df4b-b630-47a1-ab80-7ad5385fcd8d\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Dataset templates along with train and evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_template = client.dataset_templates().find_by_name_like(\"PIMA\")[\"_embedded\"][\n",
    "    \"datasetTemplates\"\n",
    "][0]\n",
    "dataset_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = client.datasets().find_by_dataset_template_id(dataset_template[\"id\"])[\n",
    "    \"_embedded\"\n",
    "][\"datasets\"]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train dataset\n",
    "\n",
    "train_dataset = [d for d in datasets if d[\"scope\"] == \"train\"][0]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get evaluate dataset\n",
    "\n",
    "evaluate_dataset = [d for d in datasets if d[\"scope\"] == \"evaluate\"][0]\n",
    "eval_dataset_id = evaluate_dataset[\"id\"]\n",
    "eval_dataset_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Default Dataset Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New API, allows users do fetch a default dataset connection\n",
    "# (notice it only works for real users, service account probably don't have personal connections)\n",
    "\n",
    "default_connection = client.user_attributes().get_default_connection()\n",
    "default_connection\n",
    "default_connection_id = default_connection[\"value\"][\"defaultDatasetConnectionId\"]\n",
    "default_connection_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a BYOM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "model_dict = {\n",
    "    \"name\": f\"{language}_Python_{uuid.uuid4().clock_seq}\",\n",
    "    \"description\": f\"{language} model defined from Python SDK\",\n",
    "    \"language\": language,\n",
    "}\n",
    "\n",
    "model_response = client.models().save(model_dict)\n",
    "model = model_response[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_id = client.trained_model_artefacts().upload_byom_model(\"PMML\", file)\n",
    "import_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import BYOM model and monitor the compute statistics job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**import_request parameters**:\n",
    "\n",
    "To skip Model Monitoring, you can remove the `modelMonitoring` JSON object and instead use the `metadata` object: \n",
    "```json\n",
    "metadata: {\n",
    "    \"language\": language,\n",
    "    \"evaluationEnabled\": False,\n",
    "    \"datasetId\": train_dataset[\"id\"],\n",
    "    \"datasetConnectionId\": default_connection_id,\n",
    "}\n",
    "```\n",
    "\n",
    "This will disable model monitoring and should be used for models that just need to be approved and deployed after importing.\n",
    "To enable model monitoring and evaluation, use the below parameters:\n",
    "\n",
    "modelMonitoring:\n",
    "- *useDefaultEvaluation* - Set to True to enable default evaluation. Set to False while using custom metrics for evaluation, performance monitoring,\n",
    "  feature and prediction drift monitoring (True is required when enabling model monitoring with default metrics)\n",
    "- *evaluationEnabled* - Set to True to enable model evaluation and performance monitoring\n",
    "- *modelType* - The type of the model, either CLASSIFICATION or REGRESSION\n",
    "- *byomColumnExpression*: The predicition expression for the model\n",
    "- *driftMonitoringEnabled*: Set to True to enable feature and prediction drift monitoring. This will run the computing statistics after importing the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_request = {\n",
    "    \"artefactImportId\": import_id,\n",
    "    \"externalId\": str(uuid.uuid4()),\n",
    "    \"modelMonitoring\": {\n",
    "        \"language\": language,\n",
    "        \"useDefaultEvaluation\": True,\n",
    "        \"evaluationEnabled\": True,\n",
    "        \"modelType\": \"CLASSIFICATION\",\n",
    "        \"byomColumnExpression\": (\n",
    "            \"CAST(CAST(json_report AS JSON).JSONExtractValue('$.predicted_HasDiabetes')\"\n",
    "            \" AS INT)\"\n",
    "        ),\n",
    "        \"driftMonitoringEnabled\": True,\n",
    "        \"datasetId\": train_dataset[\"id\"],\n",
    "        \"datasetConnectionId\": default_connection_id,\n",
    "    },\n",
    "}\n",
    "\n",
    "response = client.models().import_byom(model, import_request)\n",
    "import_job_id = response[\"id\"]\n",
    "\n",
    "client.jobs().wait(import_job_id)\n",
    "\n",
    "print(\"Model imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_jobs = client.jobs().find_all()\n",
    "compute_stats_job = None\n",
    "\n",
    "for jobs in running_jobs[\"_embedded\"][\"jobs\"]:\n",
    "    if jobs[\"type\"] == \"COMPUTE_STATISTICS\" and jobs[\"modelId\"] == model:\n",
    "        compute_stats_job = jobs[\"id\"]\n",
    "\n",
    "job = client.jobs().find_by_id(id=compute_stats_job, projection=\"expandJob\")\n",
    "client.jobs().wait(compute_stats_job)\n",
    "print(\"Compute statistics completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_model_id = response[\"metadata\"][\"trainedModel\"][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "eval_request = {\n",
    "    \"datasetId\": eval_dataset_id,\n",
    "    \"datasetConnectionId\": default_connection_id,\n",
    "    \"automationOverrides\": {\n",
    "        \"resources\": {\"memory\": \"500m\", \"cpu\": \"0.5\"},\n",
    "        \"dockerImage\": \"artifacts.td.teradata.com/tdproduct-docker-snapshot/avmo/vmo-python-base:3.9.3\",\n",
    "    },\n",
    "}\n",
    "\n",
    "evaluate_response = client.trained_models().evaluate(imported_model_id, eval_request)\n",
    "\n",
    "eval_job_id = evaluate_response[\"id\"]\n",
    "client.jobs().wait(eval_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.trained_models().approve(imported_model_id, comments=\"LGTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deploy model and monitor batch prediction job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy_request = {\n",
    "    \"engineType\": \"IN_VANTAGE\",\n",
    "    \"engineTypeConfig\": {\n",
    "        \"dockerImage\": \"artifacts.td.teradata.com/tdproduct-docker-snapshot/avmo/vmo-python-base:3.9.3\",\n",
    "        \"engine\": \"byom\",\n",
    "        \"resources\": {\n",
    "            \"memory\": \"500m\",\n",
    "            \"cpu\": \"0.5\",\n",
    "        },\n",
    "    },\n",
    "    \"language\": \"PMML\",\n",
    "    \"datasetConnectionId\": default_connection_id,\n",
    "    \"byomModelLocation\": {\"database\": \"trng_modelops\", \"table\": \"aoa_byom_models\"},\n",
    "    \"datasetTemplateId\": dataset_template[\"id\"],\n",
    "    \"cron\": \"@once\",\n",
    "    \"publishOnly\": \"false\",\n",
    "    \"customProperties\": {},\n",
    "}\n",
    "\n",
    "deploy_response = client.trained_models().deploy(imported_model_id, deploy_request)\n",
    "deploy_job_id = deploy_response[\"id\"]\n",
    "\n",
    "client.jobs().wait(deploy_job_id)\n",
    "print(\"Model deployed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job_id = \"\"\n",
    "running_jobs = client.jobs().find_all()\n",
    "\n",
    "for jobs in running_jobs[\"_embedded\"][\"jobs\"]:\n",
    "    if jobs[\"type\"] == \"BATCH_PREDICTION\" and jobs[\"modelId\"] == model:\n",
    "        batch_job_id = jobs[\"id\"]\n",
    "\n",
    "running_msg_printed = False\n",
    "\n",
    "client.jobs().wait(batch_job_id)\n",
    "print(\"Batch prediction completed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
